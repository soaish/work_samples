{"cells":[{"cell_type":"markdown","metadata":{"id":"VwuHftglu7gP"},"source":["# Coin Run Game\n","\n","The [Coin Run](https://github.com/openai/coinrun) is a simple 2D platform jumping game where the agent must get to the coin at the end of the level. Whereas the orignal game generates randomly-generated levels, I have hacked the game to give repeatable levels and identified a few levels to try out."]},{"cell_type":"markdown","metadata":{"id":"BLxdm_vNds6Q"},"source":["Those new to convolutional neural networks may find this [example](https://colab.research.google.com/drive/1740OwEI4oi5QlPtq4UFd3ha44yxef7gU) helpful."]},{"cell_type":"markdown","metadata":{"id":"UbcPfbI2CBGr"},"source":["# Installation\n","\n","Run the following cells"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rodhvmBKCDI6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712956144321,"user_tz":240,"elapsed":10023,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"8479347e-89a4-44e7-a5d4-fad10d6a2cc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","Note, selecting 'libtcmalloc-minimal4' for glob 'libtcmalloc*'\n","The following packages will be REMOVED:\n","  google-perftools libgoogle-perftools4 libtcmalloc-minimal4\n","0 upgraded, 0 newly installed, 3 to remove and 45 not upgraded.\n","After this operation, 1,817 kB disk space will be freed.\n","(Reading database ... 121752 files and directories currently installed.)\n","Removing google-perftools (2.9.1-0ubuntu3) ...\n","Removing libgoogle-perftools4:amd64 (2.9.1-0ubuntu3) ...\n","Removing libtcmalloc-minimal4:amd64 (2.9.1-0ubuntu3) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n"]}],"source":["import os\n","#del os.environ['LD_PRELOAD']\n","!apt-get remove libtcmalloc*"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"u3gG-QharKJY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712956230714,"user_tz":240,"elapsed":86398,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"7e5c2c98-9216-490a-d6f7-f874b65bcec4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [Connected to cloud.r-\r                                                                                                    \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","\r                                                                                                    \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [808 kB]\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,974 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,176 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [61.3 kB]\n","Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,135 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.7 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,691 kB]\n","Fetched 11.6 MB in 5s (2,152 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","The following additional packages will be installed:\n","  hwloc-nox libmpich-dev libmpich12 libslurm37\n","Suggested packages:\n","  mpich-doc\n","The following NEW packages will be installed:\n","  hwloc-nox libmpich-dev libmpich12 libslurm37 mpich\n","0 upgraded, 5 newly installed, 0 to remove and 46 not upgraded.\n","Need to get 14.2 MB of archives.\n","After this operation, 102 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libslurm37 amd64 21.08.5-2ubuntu1 [542 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 hwloc-nox amd64 2.7.0-2ubuntu1 [205 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich12 amd64 4.0-3 [5,866 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mpich amd64 4.0-3 [197 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich-dev amd64 4.0-3 [7,375 kB]\n","Fetched 14.2 MB in 2s (8,185 kB/s)\n","Selecting previously unselected package libslurm37.\n","(Reading database ... 121727 files and directories currently installed.)\n","Preparing to unpack .../libslurm37_21.08.5-2ubuntu1_amd64.deb ...\n","Unpacking libslurm37 (21.08.5-2ubuntu1) ...\n","Selecting previously unselected package hwloc-nox.\n","Preparing to unpack .../hwloc-nox_2.7.0-2ubuntu1_amd64.deb ...\n","Unpacking hwloc-nox (2.7.0-2ubuntu1) ...\n","Selecting previously unselected package libmpich12:amd64.\n","Preparing to unpack .../libmpich12_4.0-3_amd64.deb ...\n","Unpacking libmpich12:amd64 (4.0-3) ...\n","Selecting previously unselected package mpich.\n","Preparing to unpack .../archives/mpich_4.0-3_amd64.deb ...\n","Unpacking mpich (4.0-3) ...\n","Selecting previously unselected package libmpich-dev:amd64.\n","Preparing to unpack .../libmpich-dev_4.0-3_amd64.deb ...\n","Unpacking libmpich-dev:amd64 (4.0-3) ...\n","Setting up libslurm37 (21.08.5-2ubuntu1) ...\n","Setting up hwloc-nox (2.7.0-2ubuntu1) ...\n","Setting up libmpich12:amd64 (4.0-3) ...\n","Setting up mpich (4.0-3) ...\n","Setting up libmpich-dev:amd64 (4.0-3) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n","The following additional packages will be installed:\n","  avahi-daemon bind9-host bind9-libs clang-tidy clang-tidy-14 clang-tools-14 gdb geoclue-2.0\n","  glib-networking glib-networking-common glib-networking-services gsettings-desktop-schemas\n","  iio-sensor-proxy libavahi-core7 libavahi-glib1 libbabeltrace1 libc6-dbg libdaemon0\n","  libdebuginfod-common libdebuginfod1 libegl-dev libevdev2 libfontenc1 libgl-dev libglu1-mesa\n","  libglu1-mesa-dev libglx-dev libgudev-1.0-0 libhyphen0 libinput-bin libinput10 libipt2\n","  libjson-glib-1.0-0 libjson-glib-1.0-common libkf5syntaxhighlighting-data\n","  libkf5syntaxhighlighting5 liblmdb0 libmaxminddb0 libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0\n","  libmtdev1 libnl-genl-3-200 libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy\n","  libqt5concurrent5 libqt5core5a libqt5dbus5 libqt5designer5 libqt5designercomponents5 libqt5gui5\n","  libqt5help5 libqt5network5 libqt5opengl5 libqt5opengl5-dev libqt5positioning5 libqt5printsupport5\n","  libqt5qml5 libqt5qmlmodels5 libqt5qmlworkerscript5 libqt5quick5 libqt5quicktest5\n","  libqt5quickwidgets5 libqt5sensors5 libqt5serialport5 libqt5sql5 libqt5sql5-sqlite libqt5svg5\n","  libqt5test5 libqt5webchannel5 libqt5webkit5 libqt5widgets5 libqt5xml5 libqt5xmlpatterns5\n","  libsoup2.4-1 libsoup2.4-common libsource-highlight-common libsource-highlight4v5 libudev1\n","  libvulkan-dev libvulkan1 libwacom-bin libwacom-common libwacom9 libwoff1 libxcb-icccm4\n","  libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0\n","  libxcb-xkb1 libxkbcommon-x11-0 libxkbfile1 libxtst6 libxxf86dga1 libyaml-cpp0.7\n","  mesa-vulkan-drivers modemmanager python3-yaml qdoc-qt5 qhelpgenerator-qt5\n","  qml-module-qtgraphicaleffects qml-module-qtqml qml-module-qtqml-models2\n","  qml-module-qtquick-controls qml-module-qtquick-layouts qml-module-qtquick-window2\n","  qml-module-qtquick2 qmlscene qt3d5-doc qt5-assistant qt5-doc qt5-gtk-platformtheme qt5-qmake-bin\n","  qt5-qmltooling-plugins qtattributionsscanner-qt5 qtbase5-dev-tools qtbase5-doc qtcharts5-doc\n","  qtchooser qtconnectivity5-doc qtcreator-data qtcreator-doc qtdatavisualization5-doc\n","  qtdeclarative5-dev-tools qtdeclarative5-doc qtgamepad5-doc qtgraphicaleffects5-doc\n","  qtlocation5-doc qtmultimedia5-doc qtnetworkauth5-doc qtquickcontrols2-5-doc qtquickcontrols5-doc\n","  qtscript5-doc qtscxml5-doc qtsensors5-doc qtserialbus5-doc qtserialport5-doc qtsvg5-doc\n","  qttools5-dev-tools qttools5-doc qttranslations5-l10n qtvirtualkeyboard5-doc qtwayland5-doc\n","  qtwebchannel5-doc qtwebengine5-doc qtwebsockets5-doc qtwebview5-doc qtx11extras5-doc\n","  qtxmlpatterns5-dev-tools qtxmlpatterns5-doc session-migration systemd-hwe-hwdb udev\n","  usb-modeswitch usb-modeswitch-data wpasupplicant x11-utils xbitmaps xterm\n","Suggested packages:\n","  avahi-autoipd gdb-doc gdbserver mmdb-bin gnome-shell | notification-daemon avahi-autoipd\n","  | zeroconf qt5-image-formats-plugins qtwayland5 firebird-dev clazy meson subversion valgrind\n","  python3-pylsp comgt wvdial wpagui libengine-pkcs11-openssl mesa-utils xfonts-cyrillic\n","The following NEW packages will be installed:\n","  avahi-daemon bind9-host bind9-libs clang-tidy clang-tidy-14 clang-tools-14 gdb geoclue-2.0\n","  glib-networking glib-networking-common glib-networking-services gsettings-desktop-schemas\n","  iio-sensor-proxy libavahi-core7 libavahi-glib1 libbabeltrace1 libc6-dbg libdaemon0\n","  libdebuginfod-common libdebuginfod1 libegl-dev libevdev2 libfontenc1 libgl-dev libglu1-mesa\n","  libglu1-mesa-dev libglx-dev libgudev-1.0-0 libhyphen0 libinput-bin libinput10 libipt2\n","  libjson-glib-1.0-0 libjson-glib-1.0-common libkf5syntaxhighlighting-data\n","  libkf5syntaxhighlighting5 liblmdb0 libmaxminddb0 libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0\n","  libmtdev1 libnl-genl-3-200 libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy\n","  libqt5concurrent5 libqt5core5a libqt5dbus5 libqt5designer5 libqt5designercomponents5 libqt5gui5\n","  libqt5help5 libqt5network5 libqt5opengl5 libqt5opengl5-dev libqt5positioning5 libqt5printsupport5\n","  libqt5qml5 libqt5qmlmodels5 libqt5qmlworkerscript5 libqt5quick5 libqt5quicktest5\n","  libqt5quickwidgets5 libqt5sensors5 libqt5serialport5 libqt5sql5 libqt5sql5-sqlite libqt5svg5\n","  libqt5test5 libqt5webchannel5 libqt5webkit5 libqt5widgets5 libqt5xml5 libqt5xmlpatterns5\n","  libsoup2.4-1 libsoup2.4-common libsource-highlight-common libsource-highlight4v5 libvulkan-dev\n","  libvulkan1 libwacom-bin libwacom-common libwacom9 libwoff1 libxcb-icccm4 libxcb-image0\n","  libxcb-keysyms1 libxcb-render-util0 libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1\n","  libxkbcommon-x11-0 libxkbfile1 libxtst6 libxxf86dga1 libyaml-cpp0.7 mesa-vulkan-drivers\n","  modemmanager python3-yaml qdoc-qt5 qhelpgenerator-qt5 qml-module-qtgraphicaleffects\n","  qml-module-qtqml qml-module-qtqml-models2 qml-module-qtquick-controls qml-module-qtquick-layouts\n","  qml-module-qtquick-window2 qml-module-qtquick2 qmlscene qt3d5-doc qt5-assistant qt5-doc\n","  qt5-gtk-platformtheme qt5-qmake qt5-qmake-bin qt5-qmltooling-plugins qtattributionsscanner-qt5\n","  qtbase5-dev qtbase5-dev-tools qtbase5-doc qtcharts5-doc qtchooser qtconnectivity5-doc qtcreator\n","  qtcreator-data qtcreator-doc qtdatavisualization5-doc qtdeclarative5-dev-tools qtdeclarative5-doc\n","  qtgamepad5-doc qtgraphicaleffects5-doc qtlocation5-doc qtmultimedia5-doc qtnetworkauth5-doc\n","  qtquickcontrols2-5-doc qtquickcontrols5-doc qtscript5-doc qtscxml5-doc qtsensors5-doc\n","  qtserialbus5-doc qtserialport5-doc qtsvg5-doc qttools5-dev-tools qttools5-doc\n","  qttranslations5-l10n qtvirtualkeyboard5-doc qtwayland5-doc qtwebchannel5-doc qtwebengine5-doc\n","  qtwebsockets5-doc qtwebview5-doc qtx11extras5-doc qtxmlpatterns5-dev-tools qtxmlpatterns5-doc\n","  session-migration systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wpasupplicant\n","  x11-utils xbitmaps xterm\n","The following packages will be upgraded:\n","  libudev1\n","1 upgraded, 168 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 215 MB of archives.\n","After this operation, 566 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblmdb0 amd64 0.9.24-1build2 [47.6 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmaxminddb0 amd64 1.5.2-1build2 [24.7 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 bind9-libs amd64 1:9.18.18-0ubuntu0.22.04.2 [1,245 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 bind9-host amd64 1:9.18.18-0ubuntu0.22.04.2 [52.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod-common all 0.186-1build1 [7,878 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n","Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n","Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n","Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n","Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n","Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n","Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\n","Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n","Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\n","Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\n","Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\n","Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\n","Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\n","Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n","Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\n","Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtquick-window2 amd64 5.15.3+dfsg-1 [26.3 kB]\n","Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlworkerscript5 amd64 5.15.3+dfsg-1 [34.4 kB]\n","Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtquick2 amd64 5.15.3+dfsg-1 [33.7 kB]\n","Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtgraphicaleffects amd64 5.15.3-1 [74.3 kB]\n","Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtqml amd64 5.15.3+dfsg-1 [17.2 kB]\n","Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtqml-models2 amd64 5.15.3+dfsg-1 [18.0 kB]\n","Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtquick-layouts amd64 5.15.3+dfsg-1 [56.0 kB]\n","Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qml-module-qtquick-controls amd64 5.15.3-1 [577 kB]\n","Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 python3-yaml amd64 5.4.1-1ubuntu1 [129 kB]\n","Get:52 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n","Get:53 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 clang-tools-14 amd64 1:14.0.0-1ubuntu1.1 [6,962 kB]\n","Get:54 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 clang-tidy-14 amd64 1:14.0.0-1ubuntu1.1 [1,626 kB]\n","Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 clang-tidy amd64 1:14.0-55~exp2 [3,456 B]\n","Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libbabeltrace1 amd64 1.5.8-2build1 [160 kB]\n","Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdebuginfod1 amd64 0.186-1build1 [12.7 kB]\n","Get:58 http://archive.ubuntu.com/ubuntu jammy/main amd64 libipt2 amd64 2.0.5-1 [46.4 kB]\n","Get:59 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight-common all 3.1.9-4.1build2 [64.5 kB]\n","Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsource-highlight4v5 amd64 3.1.9-4.1build2 [207 kB]\n","Get:61 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gdb amd64 12.1-0ubuntu1~22.04 [3,919 kB]\n","Get:62 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\n","Get:63 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n","Get:64 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n","Get:65 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.3 [263 kB]\n","Get:66 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n","Get:67 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n","Get:68 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n","Get:69 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n","Get:70 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n","Get:71 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n","Get:72 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n","Get:73 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsoup2.4-common all 2.74.2-3 [4,008 B]\n","Get:74 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsoup2.4-1 amd64 2.74.2-3 [287 kB]\n","Get:75 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\n","Get:76 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\n","Get:77 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n","Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n","Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n","Get:80 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:81 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n","Get:82 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n","Get:83 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkf5syntaxhighlighting-data all 5.92.0-0ubuntu1 [69.5 kB]\n","Get:84 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkf5syntaxhighlighting5 amd64 5.92.0-0ubuntu1 [1,527 kB]\n","Get:85 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.1 [191 kB]\n","Get:86 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.1 [6,130 B]\n","Get:87 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\n","Get:88 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\n","Get:89 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\n","Get:90 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\n","Get:91 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5concurrent5 amd64 5.15.3+dfsg-2ubuntu0.2 [36.3 kB]\n","Get:92 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5xml5 amd64 5.15.3+dfsg-2ubuntu0.2 [124 kB]\n","Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5designer5 amd64 5.15.3-1 [2,832 kB]\n","Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5designercomponents5 amd64 5.15.3-1 [796 kB]\n","Get:95 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5sql5 amd64 5.15.3+dfsg-2ubuntu0.2 [123 kB]\n","Get:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5help5 amd64 5.15.3-1 [162 kB]\n","Get:97 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5opengl5 amd64 5.15.3+dfsg-2ubuntu0.2 [153 kB]\n","Get:98 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5test5 amd64 5.15.3+dfsg-2ubuntu0.2 [152 kB]\n","Get:99 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n","Get:100 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan-dev amd64 1.3.204.1-2 [892 kB]\n","Get:101 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-qmake-bin amd64 5.15.3+dfsg-2ubuntu0.2 [1,126 kB]\n","Get:102 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtchooser amd64 66-2build1 [24.7 kB]\n","Get:103 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-qmake amd64 5.15.3+dfsg-2ubuntu0.2 [208 kB]\n","Get:104 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qtbase5-dev-tools amd64 5.15.3+dfsg-2ubuntu0.2 [819 kB]\n","Get:105 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qtbase5-dev amd64 5.15.3+dfsg-2ubuntu0.2 [1,135 kB]\n","Get:106 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5opengl5-dev amd64 5.15.3+dfsg-2ubuntu0.2 [42.3 kB]\n","Get:107 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quicktest5 amd64 5.15.3+dfsg-1 [58.2 kB]\n","Get:108 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quickwidgets5 amd64 5.15.3+dfsg-1 [39.9 kB]\n","Get:109 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5serialport5 amd64 5.15.3-1 [34.6 kB]\n","Get:110 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5sql5-sqlite amd64 5.15.3+dfsg-2ubuntu0.2 [53.0 kB]\n","Get:111 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5xmlpatterns5 amd64 5.15.3-1 [901 kB]\n","Get:112 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n","Get:113 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:114 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n","Get:115 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n","Get:116 http://archive.ubuntu.com/ubuntu jammy/main amd64 libyaml-cpp0.7 amd64 0.7.0+dfsg-8build1 [97.7 kB]\n","Get:117 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.2 [10.7 MB]\n","Get:118 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.3 [1,094 kB]\n","Get:119 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qdoc-qt5 amd64 5.15.3-1 [632 kB]\n","Get:120 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qhelpgenerator-qt5 amd64 5.15.3-1 [60.7 kB]\n","Get:121 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qmlscene amd64 5.15.3+dfsg-1 [30.7 kB]\n","Get:122 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qt3d5-doc all 5.15.3+dfsg-1 [3,738 kB]\n","Get:123 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qt5-assistant amd64 5.15.3-1 [373 kB]\n","Get:124 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qtbase5-doc all 5.15.3+dfsg-2ubuntu0.2 [24.2 MB]\n","Get:125 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtcharts5-doc all 5.15.3-1 [4,710 kB]\n","Get:126 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtconnectivity5-doc all 5.15.3-1 [2,096 kB]\n","Get:127 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtdatavisualization5-doc all 5.15.3-1 [3,582 kB]\n","Get:128 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtdeclarative5-doc all 5.15.3+dfsg-1 [9,563 kB]\n","Get:129 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtgamepad5-doc all 5.15.3-1 [133 kB]\n","Get:130 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtgraphicaleffects5-doc all 5.15.3-1 [13.1 MB]\n","Get:131 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtlocation5-doc all 5.15.3+dfsg-3 [2,381 kB]\n","Get:132 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtmultimedia5-doc all 5.15.3-1 [1,503 kB]\n","Get:133 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtnetworkauth5-doc all 5.15.3-1 [132 kB]\n","Get:134 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtquickcontrols2-5-doc all 5.15.3+dfsg-1 [5,307 kB]\n","Get:135 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtquickcontrols5-doc all 5.15.3-1 [1,546 kB]\n","Get:136 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtscript5-doc all 5.15.3+dfsg-1 [322 kB]\n","Get:137 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtscxml5-doc all 5.15.3-1 [365 kB]\n","Get:138 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtsensors5-doc all 5.15.3-1 [1,977 kB]\n","Get:139 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtserialbus5-doc all 5.15.3-1 [224 kB]\n","Get:140 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtserialport5-doc all 5.15.3-1 [157 kB]\n","Get:141 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtsvg5-doc all 5.15.3-1 [144 kB]\n","Get:142 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttools5-doc all 5.15.3-1 [3,411 kB]\n","Get:143 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtvirtualkeyboard5-doc all 5.15.3+dfsg-1 [1,081 kB]\n","Get:144 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtwayland5-doc all 5.15.3-1 [395 kB]\n","Get:145 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtwebchannel5-doc all 5.15.3-1 [95.8 kB]\n","Get:146 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtwebengine5-doc all 5.15.9+dfsg-1 [1,923 kB]\n","Get:147 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtwebsockets5-doc all 5.15.3-1 [172 kB]\n","Get:148 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtwebview5-doc all 5.15.3-1build1 [68.5 kB]\n","Get:149 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtx11extras5-doc all 5.15.3-1 [25.6 kB]\n","Get:150 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtxmlpatterns5-doc all 5.15.3-1 [541 kB]\n","Get:151 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qt5-doc all 5.15.3-1 [6,295 kB]\n","Get:152 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n","Get:153 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qt5-qmltooling-plugins amd64 5.15.3+dfsg-1 [193 kB]\n","Get:154 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtattributionsscanner-qt5 amd64 5.15.3-1 [32.5 kB]\n","Get:155 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtcreator-data all 6.0.2-2build1 [3,069 kB]\n","Get:156 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtcreator amd64 6.0.2-2build1 [18.0 MB]\n","Get:157 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtcreator-doc all 6.0.2-2build1 [13.2 MB]\n","Get:158 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtdeclarative5-dev-tools amd64 5.15.3+dfsg-1 [688 kB]\n","Get:159 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttools5-dev-tools amd64 5.15.3-1 [1,129 kB]\n","Get:160 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n","Get:161 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qtxmlpatterns5-dev-tools amd64 5.15.3-1 [29.8 kB]\n","Get:162 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n","Get:163 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2 [1,481 kB]\n","Get:164 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n","Get:165 http://archive.ubuntu.com/ubuntu jammy/main amd64 xbitmaps all 1.1.1-2.1ubuntu1 [23.4 kB]\n","Get:166 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xterm amd64 372-1ubuntu1 [857 kB]\n","Get:167 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc6-dbg amd64 2.35-0ubuntu3.6 [13.8 MB]\n","Get:168 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\n","Get:169 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\n","Fetched 215 MB in 26s (8,284 kB/s)\n","Extracting templates from packages: 100%\n","Preconfiguring packages ...\n","Selecting previously unselected package libavahi-core7:amd64.\n","(Reading database ... 121853 files and directories currently installed.)\n","Preparing to unpack .../00-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\n","Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n","Selecting previously unselected package libdaemon0:amd64.\n","Preparing to unpack .../01-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n","Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n","Selecting previously unselected package liblmdb0:amd64.\n","Preparing to unpack .../02-liblmdb0_0.9.24-1build2_amd64.deb ...\n","Unpacking liblmdb0:amd64 (0.9.24-1build2) ...\n","Selecting previously unselected package libmaxminddb0:amd64.\n","Preparing to unpack .../03-libmaxminddb0_1.5.2-1build2_amd64.deb ...\n","Unpacking libmaxminddb0:amd64 (1.5.2-1build2) ...\n","Selecting previously unselected package bind9-libs:amd64.\n","Preparing to unpack .../04-bind9-libs_1%3a9.18.18-0ubuntu0.22.04.2_amd64.deb ...\n","Unpacking bind9-libs:amd64 (1:9.18.18-0ubuntu0.22.04.2) ...\n","Selecting previously unselected package bind9-host.\n","Preparing to unpack .../05-bind9-host_1%3a9.18.18-0ubuntu0.22.04.2_amd64.deb ...\n","Unpacking bind9-host (1:9.18.18-0ubuntu0.22.04.2) ...\n","Selecting previously unselected package avahi-daemon.\n","Preparing to unpack .../06-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\n","Unpacking avahi-daemon (0.8-5ubuntu5.2) ...\n","Selecting previously unselected package libdebuginfod-common.\n","Preparing to unpack .../07-libdebuginfod-common_0.186-1build1_all.deb ...\n","Unpacking libdebuginfod-common (0.186-1build1) ...\n","Selecting previously unselected package libqt5core5a:amd64.\n","Preparing to unpack .../08-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libevdev2:amd64.\n","Preparing to unpack .../09-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n","Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n","Selecting previously unselected package libmtdev1:amd64.\n","Preparing to unpack .../10-libmtdev1_1.1.6-1build4_amd64.deb ...\n","Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n","Preparing to unpack .../11-libudev1_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n","Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package libgudev-1.0-0:amd64.\n","(Reading database ... 121959 files and directories currently installed.)\n","Preparing to unpack .../000-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n","Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n","Selecting previously unselected package libwacom-common.\n","Preparing to unpack .../001-libwacom-common_2.2.0-1_all.deb ...\n","Unpacking libwacom-common (2.2.0-1) ...\n","Selecting previously unselected package libwacom9:amd64.\n","Preparing to unpack .../002-libwacom9_2.2.0-1_amd64.deb ...\n","Unpacking libwacom9:amd64 (2.2.0-1) ...\n","Selecting previously unselected package libinput-bin.\n","Preparing to unpack .../003-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n","Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n","Selecting previously unselected package libinput10:amd64.\n","Preparing to unpack .../004-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n","Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n","Selecting previously unselected package libmd4c0:amd64.\n","Preparing to unpack .../005-libmd4c0_0.4.8-1_amd64.deb ...\n","Unpacking libmd4c0:amd64 (0.4.8-1) ...\n","Selecting previously unselected package libqt5dbus5:amd64.\n","Preparing to unpack .../006-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5network5:amd64.\n","Preparing to unpack .../007-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libxcb-icccm4:amd64.\n","Preparing to unpack .../008-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n","Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Selecting previously unselected package libxcb-util1:amd64.\n","Preparing to unpack .../009-libxcb-util1_0.4.0-1build2_amd64.deb ...\n","Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n","Selecting previously unselected package libxcb-image0:amd64.\n","Preparing to unpack .../010-libxcb-image0_0.4.0-2_amd64.deb ...\n","Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n","Selecting previously unselected package libxcb-keysyms1:amd64.\n","Preparing to unpack .../011-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n","Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Selecting previously unselected package libxcb-render-util0:amd64.\n","Preparing to unpack .../012-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n","Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Selecting previously unselected package libxcb-xinerama0:amd64.\n","Preparing to unpack .../013-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-xinput0:amd64.\n","Preparing to unpack .../014-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxcb-xkb1:amd64.\n","Preparing to unpack .../015-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n","Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Selecting previously unselected package libxkbcommon-x11-0:amd64.\n","Preparing to unpack .../016-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n","Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libqt5gui5:amd64.\n","Preparing to unpack .../017-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5widgets5:amd64.\n","Preparing to unpack .../018-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5svg5:amd64.\n","Preparing to unpack .../019-libqt5svg5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libhyphen0:amd64.\n","Preparing to unpack .../020-libhyphen0_2.8.8-7build2_amd64.deb ...\n","Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n","Selecting previously unselected package libqt5positioning5:amd64.\n","Preparing to unpack .../021-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n","Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n","Selecting previously unselected package libqt5printsupport5:amd64.\n","Preparing to unpack .../022-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5qml5:amd64.\n","Preparing to unpack .../023-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5qmlmodels5:amd64.\n","Preparing to unpack .../024-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5quick5:amd64.\n","Preparing to unpack .../025-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5sensors5:amd64.\n","Preparing to unpack .../026-libqt5sensors5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libqt5webchannel5:amd64.\n","Preparing to unpack .../027-libqt5webchannel5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libwoff1:amd64.\n","Preparing to unpack .../028-libwoff1_1.0.2-1build4_amd64.deb ...\n","Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n","Selecting previously unselected package libqt5webkit5:amd64.\n","Preparing to unpack .../029-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n","Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n","Selecting previously unselected package qml-module-qtquick-window2:amd64.\n","Preparing to unpack .../030-qml-module-qtquick-window2_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qml-module-qtquick-window2:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5qmlworkerscript5:amd64.\n","Preparing to unpack .../031-libqt5qmlworkerscript5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5qmlworkerscript5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qml-module-qtquick2:amd64.\n","Preparing to unpack .../032-qml-module-qtquick2_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qml-module-qtquick2:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qml-module-qtgraphicaleffects:amd64.\n","Preparing to unpack .../033-qml-module-qtgraphicaleffects_5.15.3-1_amd64.deb ...\n","Unpacking qml-module-qtgraphicaleffects:amd64 (5.15.3-1) ...\n","Selecting previously unselected package qml-module-qtqml:amd64.\n","Preparing to unpack .../034-qml-module-qtqml_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qml-module-qtqml:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qml-module-qtqml-models2:amd64.\n","Preparing to unpack .../035-qml-module-qtqml-models2_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qml-module-qtqml-models2:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qml-module-qtquick-layouts:amd64.\n","Preparing to unpack .../036-qml-module-qtquick-layouts_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qml-module-qtquick-layouts:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qml-module-qtquick-controls:amd64.\n","Preparing to unpack .../037-qml-module-qtquick-controls_5.15.3-1_amd64.deb ...\n","Unpacking qml-module-qtquick-controls:amd64 (5.15.3-1) ...\n","Selecting previously unselected package python3-yaml.\n","Preparing to unpack .../038-python3-yaml_5.4.1-1ubuntu1_amd64.deb ...\n","Unpacking python3-yaml (5.4.1-1ubuntu1) ...\n","Selecting previously unselected package udev.\n","Preparing to unpack .../039-udev_249.11-0ubuntu3.12_amd64.deb ...\n","Unpacking udev (249.11-0ubuntu3.12) ...\n","Selecting previously unselected package clang-tools-14.\n","Preparing to unpack .../040-clang-tools-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n","Unpacking clang-tools-14 (1:14.0.0-1ubuntu1.1) ...\n","Selecting previously unselected package clang-tidy-14.\n","Preparing to unpack .../041-clang-tidy-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n","Unpacking clang-tidy-14 (1:14.0.0-1ubuntu1.1) ...\n","Selecting previously unselected package clang-tidy.\n","Preparing to unpack .../042-clang-tidy_1%3a14.0-55~exp2_amd64.deb ...\n","Unpacking clang-tidy (1:14.0-55~exp2) ...\n","Selecting previously unselected package libbabeltrace1:amd64.\n","Preparing to unpack .../043-libbabeltrace1_1.5.8-2build1_amd64.deb ...\n","Unpacking libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Selecting previously unselected package libdebuginfod1:amd64.\n","Preparing to unpack .../044-libdebuginfod1_0.186-1build1_amd64.deb ...\n","Unpacking libdebuginfod1:amd64 (0.186-1build1) ...\n","Selecting previously unselected package libipt2.\n","Preparing to unpack .../045-libipt2_2.0.5-1_amd64.deb ...\n","Unpacking libipt2 (2.0.5-1) ...\n","Selecting previously unselected package libsource-highlight-common.\n","Preparing to unpack .../046-libsource-highlight-common_3.1.9-4.1build2_all.deb ...\n","Unpacking libsource-highlight-common (3.1.9-4.1build2) ...\n","Selecting previously unselected package libsource-highlight4v5.\n","Preparing to unpack .../047-libsource-highlight4v5_3.1.9-4.1build2_amd64.deb ...\n","Unpacking libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Selecting previously unselected package gdb.\n","Preparing to unpack .../048-gdb_12.1-0ubuntu1~22.04_amd64.deb ...\n","Unpacking gdb (12.1-0ubuntu1~22.04) ...\n","Selecting previously unselected package libavahi-glib1:amd64.\n","Preparing to unpack .../049-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\n","Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n","Selecting previously unselected package libjson-glib-1.0-common.\n","Preparing to unpack .../050-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n","Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n","Selecting previously unselected package libjson-glib-1.0-0:amd64.\n","Preparing to unpack .../051-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n","Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n","Selecting previously unselected package libmm-glib0:amd64.\n","Preparing to unpack .../052-libmm-glib0_1.20.0-1~ubuntu22.04.3_amd64.deb ...\n","Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.3) ...\n","Selecting previously unselected package libnotify4:amd64.\n","Preparing to unpack .../053-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n","Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n","Selecting previously unselected package libproxy1v5:amd64.\n","Preparing to unpack .../054-libproxy1v5_0.4.17-2_amd64.deb ...\n","Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n","Selecting previously unselected package glib-networking-common.\n","Preparing to unpack .../055-glib-networking-common_2.72.0-1_all.deb ...\n","Unpacking glib-networking-common (2.72.0-1) ...\n","Selecting previously unselected package glib-networking-services.\n","Preparing to unpack .../056-glib-networking-services_2.72.0-1_amd64.deb ...\n","Unpacking glib-networking-services (2.72.0-1) ...\n","Selecting previously unselected package session-migration.\n","Preparing to unpack .../057-session-migration_0.3.6_amd64.deb ...\n","Unpacking session-migration (0.3.6) ...\n","Selecting previously unselected package gsettings-desktop-schemas.\n","Preparing to unpack .../058-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n","Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n","Selecting previously unselected package glib-networking:amd64.\n","Preparing to unpack .../059-glib-networking_2.72.0-1_amd64.deb ...\n","Unpacking glib-networking:amd64 (2.72.0-1) ...\n","Selecting previously unselected package libsoup2.4-common.\n","Preparing to unpack .../060-libsoup2.4-common_2.74.2-3_all.deb ...\n","Unpacking libsoup2.4-common (2.74.2-3) ...\n","Selecting previously unselected package libsoup2.4-1:amd64.\n","Preparing to unpack .../061-libsoup2.4-1_2.74.2-3_amd64.deb ...\n","Unpacking libsoup2.4-1:amd64 (2.74.2-3) ...\n","Selecting previously unselected package geoclue-2.0.\n","Preparing to unpack .../062-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n","Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n","Selecting previously unselected package iio-sensor-proxy.\n","Preparing to unpack .../063-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n","Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n","Selecting previously unselected package libglx-dev:amd64.\n","Preparing to unpack .../064-libglx-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglx-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl-dev:amd64.\n","Preparing to unpack .../065-libgl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libegl-dev:amd64.\n","Preparing to unpack .../066-libegl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libegl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../067-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libglu1-mesa:amd64.\n","Preparing to unpack .../068-libglu1-mesa_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libglu1-mesa-dev:amd64.\n","Preparing to unpack .../069-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libkf5syntaxhighlighting-data.\n","Preparing to unpack .../070-libkf5syntaxhighlighting-data_5.92.0-0ubuntu1_all.deb ...\n","Unpacking libkf5syntaxhighlighting-data (5.92.0-0ubuntu1) ...\n","Selecting previously unselected package libkf5syntaxhighlighting5:amd64.\n","Preparing to unpack .../071-libkf5syntaxhighlighting5_5.92.0-0ubuntu1_amd64.deb ...\n","Unpacking libkf5syntaxhighlighting5:amd64 (5.92.0-0ubuntu1) ...\n","Selecting previously unselected package libmbim-glib4:amd64.\n","Preparing to unpack .../072-libmbim-glib4_1.28.0-1~ubuntu20.04.1_amd64.deb ...\n","Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.1) ...\n","Selecting previously unselected package libmbim-proxy.\n","Preparing to unpack .../073-libmbim-proxy_1.28.0-1~ubuntu20.04.1_amd64.deb ...\n","Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.1) ...\n","Selecting previously unselected package libnl-genl-3-200:amd64.\n","Preparing to unpack .../074-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n","Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n","Selecting previously unselected package libnss-mdns:amd64.\n","Preparing to unpack .../075-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n","Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n","Selecting previously unselected package libqmi-glib5:amd64.\n","Preparing to unpack .../076-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n","Selecting previously unselected package libqmi-proxy.\n","Preparing to unpack .../077-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n","Selecting previously unselected package libqt5concurrent5:amd64.\n","Preparing to unpack .../078-libqt5concurrent5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5concurrent5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5xml5:amd64.\n","Preparing to unpack .../079-libqt5xml5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5xml5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5designer5:amd64.\n","Preparing to unpack .../080-libqt5designer5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5designer5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libqt5designercomponents5:amd64.\n","Preparing to unpack .../081-libqt5designercomponents5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5designercomponents5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libqt5sql5:amd64.\n","Preparing to unpack .../082-libqt5sql5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5sql5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5help5:amd64.\n","Preparing to unpack .../083-libqt5help5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5help5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libqt5opengl5:amd64.\n","Preparing to unpack .../084-libqt5opengl5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5opengl5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5test5:amd64.\n","Preparing to unpack .../085-libqt5test5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5test5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libvulkan1:amd64.\n","Preparing to unpack .../086-libvulkan1_1.3.204.1-2_amd64.deb ...\n","Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n","Selecting previously unselected package libvulkan-dev:amd64.\n","Preparing to unpack .../087-libvulkan-dev_1.3.204.1-2_amd64.deb ...\n","Unpacking libvulkan-dev:amd64 (1.3.204.1-2) ...\n","Selecting previously unselected package qt5-qmake-bin.\n","Preparing to unpack .../088-qt5-qmake-bin_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qt5-qmake-bin (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qtchooser.\n","Preparing to unpack .../089-qtchooser_66-2build1_amd64.deb ...\n","Unpacking qtchooser (66-2build1) ...\n","Selecting previously unselected package qt5-qmake:amd64.\n","Preparing to unpack .../090-qt5-qmake_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qt5-qmake:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qtbase5-dev-tools.\n","Preparing to unpack .../091-qtbase5-dev-tools_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qtbase5-dev-tools (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qtbase5-dev:amd64.\n","Preparing to unpack .../092-qtbase5-dev_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qtbase5-dev:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5opengl5-dev:amd64.\n","Preparing to unpack .../093-libqt5opengl5-dev_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5opengl5-dev:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5quicktest5:amd64.\n","Preparing to unpack .../094-libqt5quicktest5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5quicktest5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5quickwidgets5:amd64.\n","Preparing to unpack .../095-libqt5quickwidgets5_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking libqt5quickwidgets5:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package libqt5serialport5:amd64.\n","Preparing to unpack .../096-libqt5serialport5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5serialport5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libqt5sql5-sqlite:amd64.\n","Preparing to unpack .../097-libqt5sql5-sqlite_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking libqt5sql5-sqlite:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package libqt5xmlpatterns5:amd64.\n","Preparing to unpack .../098-libqt5xmlpatterns5_5.15.3-1_amd64.deb ...\n","Unpacking libqt5xmlpatterns5:amd64 (5.15.3-1) ...\n","Selecting previously unselected package libwacom-bin.\n","Preparing to unpack .../099-libwacom-bin_2.2.0-1_amd64.deb ...\n","Unpacking libwacom-bin (2.2.0-1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../100-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package libxtst6:amd64.\n","Preparing to unpack .../101-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n","Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n","Selecting previously unselected package libxxf86dga1:amd64.\n","Preparing to unpack .../102-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Selecting previously unselected package libyaml-cpp0.7:amd64.\n","Preparing to unpack .../103-libyaml-cpp0.7_0.7.0+dfsg-8build1_amd64.deb ...\n","Unpacking libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n","Selecting previously unselected package mesa-vulkan-drivers:amd64.\n","Preparing to unpack .../104-mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n","Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Selecting previously unselected package modemmanager.\n","Preparing to unpack .../105-modemmanager_1.20.0-1~ubuntu22.04.3_amd64.deb ...\n","Unpacking modemmanager (1.20.0-1~ubuntu22.04.3) ...\n","Selecting previously unselected package qdoc-qt5.\n","Preparing to unpack .../106-qdoc-qt5_5.15.3-1_amd64.deb ...\n","Unpacking qdoc-qt5 (5.15.3-1) ...\n","Selecting previously unselected package qhelpgenerator-qt5.\n","Preparing to unpack .../107-qhelpgenerator-qt5_5.15.3-1_amd64.deb ...\n","Unpacking qhelpgenerator-qt5 (5.15.3-1) ...\n","Selecting previously unselected package qmlscene.\n","Preparing to unpack .../108-qmlscene_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qmlscene (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qt3d5-doc.\n","Preparing to unpack .../109-qt3d5-doc_5.15.3+dfsg-1_all.deb ...\n","Unpacking qt3d5-doc (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qt5-assistant.\n","Preparing to unpack .../110-qt5-assistant_5.15.3-1_amd64.deb ...\n","Unpacking qt5-assistant (5.15.3-1) ...\n","Selecting previously unselected package qtbase5-doc.\n","Preparing to unpack .../111-qtbase5-doc_5.15.3+dfsg-2ubuntu0.2_all.deb ...\n","Unpacking qtbase5-doc (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qtcharts5-doc.\n","Preparing to unpack .../112-qtcharts5-doc_5.15.3-1_all.deb ...\n","Unpacking qtcharts5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtconnectivity5-doc.\n","Preparing to unpack .../113-qtconnectivity5-doc_5.15.3-1_all.deb ...\n","Unpacking qtconnectivity5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtdatavisualization5-doc.\n","Preparing to unpack .../114-qtdatavisualization5-doc_5.15.3-1_all.deb ...\n","Unpacking qtdatavisualization5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtdeclarative5-doc.\n","Preparing to unpack .../115-qtdeclarative5-doc_5.15.3+dfsg-1_all.deb ...\n","Unpacking qtdeclarative5-doc (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qtgamepad5-doc.\n","Preparing to unpack .../116-qtgamepad5-doc_5.15.3-1_all.deb ...\n","Unpacking qtgamepad5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtgraphicaleffects5-doc.\n","Preparing to unpack .../117-qtgraphicaleffects5-doc_5.15.3-1_all.deb ...\n","Unpacking qtgraphicaleffects5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtlocation5-doc.\n","Preparing to unpack .../118-qtlocation5-doc_5.15.3+dfsg-3_all.deb ...\n","Unpacking qtlocation5-doc (5.15.3+dfsg-3) ...\n","Selecting previously unselected package qtmultimedia5-doc.\n","Preparing to unpack .../119-qtmultimedia5-doc_5.15.3-1_all.deb ...\n","Unpacking qtmultimedia5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtnetworkauth5-doc.\n","Preparing to unpack .../120-qtnetworkauth5-doc_5.15.3-1_all.deb ...\n","Unpacking qtnetworkauth5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtquickcontrols2-5-doc.\n","Preparing to unpack .../121-qtquickcontrols2-5-doc_5.15.3+dfsg-1_all.deb ...\n","Unpacking qtquickcontrols2-5-doc (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qtquickcontrols5-doc.\n","Preparing to unpack .../122-qtquickcontrols5-doc_5.15.3-1_all.deb ...\n","Unpacking qtquickcontrols5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtscript5-doc.\n","Preparing to unpack .../123-qtscript5-doc_5.15.3+dfsg-1_all.deb ...\n","Unpacking qtscript5-doc (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qtscxml5-doc.\n","Preparing to unpack .../124-qtscxml5-doc_5.15.3-1_all.deb ...\n","Unpacking qtscxml5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtsensors5-doc.\n","Preparing to unpack .../125-qtsensors5-doc_5.15.3-1_all.deb ...\n","Unpacking qtsensors5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtserialbus5-doc.\n","Preparing to unpack .../126-qtserialbus5-doc_5.15.3-1_all.deb ...\n","Unpacking qtserialbus5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtserialport5-doc.\n","Preparing to unpack .../127-qtserialport5-doc_5.15.3-1_all.deb ...\n","Unpacking qtserialport5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtsvg5-doc.\n","Preparing to unpack .../128-qtsvg5-doc_5.15.3-1_all.deb ...\n","Unpacking qtsvg5-doc (5.15.3-1) ...\n","Selecting previously unselected package qttools5-doc.\n","Preparing to unpack .../129-qttools5-doc_5.15.3-1_all.deb ...\n","Unpacking qttools5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtvirtualkeyboard5-doc.\n","Preparing to unpack .../130-qtvirtualkeyboard5-doc_5.15.3+dfsg-1_all.deb ...\n","Unpacking qtvirtualkeyboard5-doc (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qtwayland5-doc.\n","Preparing to unpack .../131-qtwayland5-doc_5.15.3-1_all.deb ...\n","Unpacking qtwayland5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtwebchannel5-doc.\n","Preparing to unpack .../132-qtwebchannel5-doc_5.15.3-1_all.deb ...\n","Unpacking qtwebchannel5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtwebengine5-doc.\n","Preparing to unpack .../133-qtwebengine5-doc_5.15.9+dfsg-1_all.deb ...\n","Unpacking qtwebengine5-doc (5.15.9+dfsg-1) ...\n","Selecting previously unselected package qtwebsockets5-doc.\n","Preparing to unpack .../134-qtwebsockets5-doc_5.15.3-1_all.deb ...\n","Unpacking qtwebsockets5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtwebview5-doc.\n","Preparing to unpack .../135-qtwebview5-doc_5.15.3-1build1_all.deb ...\n","Unpacking qtwebview5-doc (5.15.3-1build1) ...\n","Selecting previously unselected package qtx11extras5-doc.\n","Preparing to unpack .../136-qtx11extras5-doc_5.15.3-1_all.deb ...\n","Unpacking qtx11extras5-doc (5.15.3-1) ...\n","Selecting previously unselected package qtxmlpatterns5-doc.\n","Preparing to unpack .../137-qtxmlpatterns5-doc_5.15.3-1_all.deb ...\n","Unpacking qtxmlpatterns5-doc (5.15.3-1) ...\n","Selecting previously unselected package qt5-doc.\n","Preparing to unpack .../138-qt5-doc_5.15.3-1_all.deb ...\n","Unpacking qt5-doc (5.15.3-1) ...\n","Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n","Preparing to unpack .../139-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n","Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Selecting previously unselected package qt5-qmltooling-plugins:amd64.\n","Preparing to unpack .../140-qt5-qmltooling-plugins_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qt5-qmltooling-plugins:amd64 (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qtattributionsscanner-qt5.\n","Preparing to unpack .../141-qtattributionsscanner-qt5_5.15.3-1_amd64.deb ...\n","Unpacking qtattributionsscanner-qt5 (5.15.3-1) ...\n","Selecting previously unselected package qtcreator-data.\n","Preparing to unpack .../142-qtcreator-data_6.0.2-2build1_all.deb ...\n","Unpacking qtcreator-data (6.0.2-2build1) ...\n","Selecting previously unselected package qtcreator.\n","Preparing to unpack .../143-qtcreator_6.0.2-2build1_amd64.deb ...\n","Unpacking qtcreator (6.0.2-2build1) ...\n","Selecting previously unselected package qtcreator-doc.\n","Preparing to unpack .../144-qtcreator-doc_6.0.2-2build1_all.deb ...\n","Unpacking qtcreator-doc (6.0.2-2build1) ...\n","Selecting previously unselected package qtdeclarative5-dev-tools.\n","Preparing to unpack .../145-qtdeclarative5-dev-tools_5.15.3+dfsg-1_amd64.deb ...\n","Unpacking qtdeclarative5-dev-tools (5.15.3+dfsg-1) ...\n","Selecting previously unselected package qttools5-dev-tools.\n","Preparing to unpack .../146-qttools5-dev-tools_5.15.3-1_amd64.deb ...\n","Unpacking qttools5-dev-tools (5.15.3-1) ...\n","Selecting previously unselected package qttranslations5-l10n.\n","Preparing to unpack .../147-qttranslations5-l10n_5.15.3-1_all.deb ...\n","Unpacking qttranslations5-l10n (5.15.3-1) ...\n","Selecting previously unselected package qtxmlpatterns5-dev-tools.\n","Preparing to unpack .../148-qtxmlpatterns5-dev-tools_5.15.3-1_amd64.deb ...\n","Unpacking qtxmlpatterns5-dev-tools (5.15.3-1) ...\n","Selecting previously unselected package systemd-hwe-hwdb.\n","Preparing to unpack .../149-systemd-hwe-hwdb_249.11.5_all.deb ...\n","Unpacking systemd-hwe-hwdb (249.11.5) ...\n","Selecting previously unselected package wpasupplicant.\n","Preparing to unpack .../150-wpasupplicant_2%3a2.10-6ubuntu2_amd64.deb ...\n","Unpacking wpasupplicant (2:2.10-6ubuntu2) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../151-x11-utils_7.7+5build2_amd64.deb ...\n","Unpacking x11-utils (7.7+5build2) ...\n","Selecting previously unselected package xbitmaps.\n","Preparing to unpack .../152-xbitmaps_1.1.1-2.1ubuntu1_all.deb ...\n","Unpacking xbitmaps (1.1.1-2.1ubuntu1) ...\n","Selecting previously unselected package xterm.\n","Preparing to unpack .../153-xterm_372-1ubuntu1_amd64.deb ...\n","Unpacking xterm (372-1ubuntu1) ...\n","Selecting previously unselected package libc6-dbg:amd64.\n","Preparing to unpack .../154-libc6-dbg_2.35-0ubuntu3.6_amd64.deb ...\n","Unpacking libc6-dbg:amd64 (2.35-0ubuntu3.6) ...\n","Selecting previously unselected package usb-modeswitch-data.\n","Preparing to unpack .../155-usb-modeswitch-data_20191128-4_all.deb ...\n","Unpacking usb-modeswitch-data (20191128-4) ...\n","Selecting previously unselected package usb-modeswitch.\n","Preparing to unpack .../156-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n","Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n","Setting up qt3d5-doc (5.15.3+dfsg-1) ...\n","Setting up liblmdb0:amd64 (0.9.24-1build2) ...\n","Setting up qtcharts5-doc (5.15.3-1) ...\n","Setting up session-migration (0.3.6) ...\n","Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service  /usr/lib/systemd/user/session-migration.service.\n","Setting up qtwayland5-doc (5.15.3-1) ...\n","Setting up qtx11extras5-doc (5.15.3-1) ...\n","Setting up libproxy1v5:amd64 (0.4.17-2) ...\n","Setting up qtxmlpatterns5-doc (5.15.3-1) ...\n","Setting up qtgamepad5-doc (5.15.3-1) ...\n","Setting up clang-tools-14 (1:14.0.0-1ubuntu1.1) ...\n","Setting up qtsensors5-doc (5.15.3-1) ...\n","Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n","Setting up libwoff1:amd64 (1.0.2-1build4) ...\n","Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n","Setting up libdebuginfod-common (0.186-1build1) ...\n","\n","Creating config file /etc/profile.d/debuginfod.sh with new version\n","\n","Creating config file /etc/profile.d/debuginfod.csh with new version\n","Setting up qtbase5-doc (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qtquickcontrols2-5-doc (5.15.3+dfsg-1) ...\n","Setting up qtnetworkauth5-doc (5.15.3-1) ...\n","Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n","Setting up libmaxminddb0:amd64 (1.5.2-1build2) ...\n","Setting up libdebuginfod1:amd64 (0.186-1build1) ...\n","Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n","Setting up qtserialbus5-doc (5.15.3-1) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n","Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n","Setting up python3-yaml (5.4.1-1ubuntu1) ...\n","Setting up libkf5syntaxhighlighting-data (5.92.0-0ubuntu1) ...\n","Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n","Setting up qttools5-doc (5.15.3-1) ...\n","Setting up qtwebchannel5-doc (5.15.3-1) ...\n","Setting up libsource-highlight-common (3.1.9-4.1build2) ...\n","Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n","Setting up libc6-dbg:amd64 (2.35-0ubuntu3.6) ...\n","Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n","Setting up libxcb-image0:amd64 (0.4.0-2) ...\n","Setting up qtdeclarative5-doc (5.15.3+dfsg-1) ...\n","Setting up qtwebsockets5-doc (5.15.3-1) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n","Setting up qtmultimedia5-doc (5.15.3-1) ...\n","Setting up qttranslations5-l10n (5.15.3-1) ...\n","Setting up qt5-qmake-bin (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qtscript5-doc (5.15.3+dfsg-1) ...\n","Setting up libyaml-cpp0.7:amd64 (0.7.0+dfsg-8build1) ...\n","Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n","Setting up clang-tidy-14 (1:14.0.0-1ubuntu1.1) ...\n","Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n","Setting up usb-modeswitch-data (20191128-4) ...\n","Setting up udev (249.11-0ubuntu3.12) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up libipt2 (2.0.5-1) ...\n","Setting up qtwebengine5-doc (5.15.9+dfsg-1) ...\n","Setting up qtwebview5-doc (5.15.3-1build1) ...\n","Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libbabeltrace1:amd64 (1.5.8-2build1) ...\n","Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n","Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n","Setting up qtsvg5-doc (5.15.3-1) ...\n","Setting up libsoup2.4-common (2.74.2-3) ...\n","Setting up systemd-hwe-hwdb (249.11.5) ...\n","Setting up qtgraphicaleffects5-doc (5.15.3-1) ...\n","Setting up qtlocation5-doc (5.15.3+dfsg-3) ...\n","Setting up qtscxml5-doc (5.15.3-1) ...\n","Setting up qtcreator-data (6.0.2-2build1) ...\n","Setting up qtserialport5-doc (5.15.3-1) ...\n","Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.3) ...\n","Setting up qtvirtualkeyboard5-doc (5.15.3+dfsg-1) ...\n","Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n","Setting up libmd4c0:amd64 (0.4.8-1) ...\n","Setting up libglx-dev:amd64 (1.4.0-1) ...\n","Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n","Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n","Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n","Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up qtcreator-doc (6.0.2-2build1) ...\n","Setting up glib-networking-common (2.72.0-1) ...\n","Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n","Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n","Setting up libqt5test5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n","Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n","First installation detected...\n","Checking NSS setup...\n","Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n","Setting up libqt5concurrent5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libgl-dev:amd64 (1.4.0-1) ...\n","Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n","Setting up xbitmaps (1.1.1-2.1ubuntu1) ...\n","Setting up qtdatavisualization5-doc (5.15.3-1) ...\n","Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.1) ...\n","Setting up qtchooser (66-2build1) ...\n","Setting up libsource-highlight4v5 (3.1.9-4.1build2) ...\n","Setting up qtquickcontrols5-doc (5.15.3-1) ...\n","Setting up libwacom-common (2.2.0-1) ...\n","Setting up qtconnectivity5-doc (5.15.3-1) ...\n","Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n","Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Setting up glib-networking-services (2.72.0-1) ...\n","Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n","Setting up libvulkan-dev:amd64 (1.3.204.1-2) ...\n","Setting up qt5-qmake:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up bind9-libs:amd64 (1:9.18.18-0ubuntu0.22.04.2) ...\n","Setting up libegl-dev:amd64 (1.4.0-1) ...\n","Setting up libwacom9:amd64 (2.2.0-1) ...\n","Setting up clang-tidy (1:14.0-55~exp2) ...\n","Setting up qdoc-qt5 (5.15.3-1) ...\n","Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n","Setting up libqt5serialport5:amd64 (5.15.3-1) ...\n","Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.1) ...\n","Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n","Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n","Setting up libqt5sql5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qt5-doc (5.15.3-1) ...\n","Setting up wpasupplicant (2:2.10-6ubuntu2) ...\n","Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service  /lib/systemd/system/wpa_supplicant.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service  /lib/systemd/system/wpa_supplicant.service.\n","Setting up qtbase5-dev-tools (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqt5xml5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up gdb (12.1-0ubuntu1~22.04) ...\n","Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n","Setting up qtattributionsscanner-qt5 (5.15.3-1) ...\n","Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n","Setting up libwacom-bin (2.2.0-1) ...\n","Setting up x11-utils (7.7+5build2) ...\n","Setting up xterm (372-1ubuntu1) ...\n","update-alternatives: using /usr/bin/xterm to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in auto mode\n","update-alternatives: using /usr/bin/lxterm to provide /usr/bin/x-terminal-emulator (x-terminal-emulator) in auto mode\n","Setting up bind9-host (1:9.18.18-0ubuntu0.22.04.2) ...\n","Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n","Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5sql5-sqlite:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qml-module-qtqml:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5xmlpatterns5:amd64 (5.15.3-1) ...\n","Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n","Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqt5help5:amd64 (5.15.3-1) ...\n","Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libqt5qmlworkerscript5:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qtbase5-dev:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up libkf5syntaxhighlighting5:amd64 (5.92.0-0ubuntu1) ...\n","Setting up avahi-daemon (0.8-5ubuntu5.2) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of force-reload.\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service  /lib/systemd/system/avahi-daemon.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service  /lib/systemd/system/avahi-daemon.service.\n","Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket  /lib/systemd/system/avahi-daemon.socket.\n","Setting up libqt5opengl5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qtxmlpatterns5-dev-tools (5.15.3-1) ...\n","Setting up qml-module-qtqml-models2:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5quicktest5:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5designer5:amd64 (5.15.3-1) ...\n","Setting up libqt5opengl5-dev:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n","Setting up qtdeclarative5-dev-tools (5.15.3+dfsg-1) ...\n","Setting up qmlscene (5.15.3+dfsg-1) ...\n","Setting up libqt5svg5:amd64 (5.15.3-1) ...\n","Setting up qhelpgenerator-qt5 (5.15.3-1) ...\n","Setting up qml-module-qtquick-window2:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n","Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n","Setting up libqt5designercomponents5:amd64 (5.15.3-1) ...\n","Setting up qml-module-qtquick-layouts:amd64 (5.15.3+dfsg-1) ...\n","Setting up qt5-qmltooling-plugins:amd64 (5.15.3+dfsg-1) ...\n","Setting up libqt5quickwidgets5:amd64 (5.15.3+dfsg-1) ...\n","Setting up qt5-assistant (5.15.3-1) ...\n","Setting up qttools5-dev-tools (5.15.3-1) ...\n","Setting up modemmanager (1.20.0-1~ubuntu22.04.3) ...\n","Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service  /lib/systemd/system/ModemManager.service.\n","Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service  /lib/systemd/system/ModemManager.service.\n","Setting up qml-module-qtquick2:amd64 (5.15.3+dfsg-1) ...\n","Setting up qml-module-qtgraphicaleffects:amd64 (5.15.3-1) ...\n","Setting up qml-module-qtquick-controls:amd64 (5.15.3-1) ...\n","Setting up qtcreator (6.0.2-2build1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.2) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n","Processing triggers for shared-mime-info (2.1-2) ...\n","Setting up glib-networking:amd64 (2.72.0-1) ...\n","Setting up libsoup2.4-1:amd64 (2.74.2-3) ...\n","Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","pkg-config is already the newest version (0.29.2-1ubuntu3).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"]}],"source":["!apt-get update\n","!apt-get install mpich build-essential\n","!apt-get install -y qtcreator qtbase5-dev qt5-qmake cmake\n","!apt-get install pkg-config"]},{"cell_type":"markdown","metadata":{"id":"yYY62z3tRkkB"},"source":["Get the coinrun game from the git repository"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"4nfOUNUHYHk4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712956247469,"user_tz":240,"elapsed":2844,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"ffe24833-c468-49dc-a850-3f36550e5dc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'coinrun-game-ai-assignment'...\n","remote: Enumerating objects: 707, done.\u001b[K\n","remote: Counting objects: 100% (61/61), done.\u001b[K\n","remote: Compressing objects: 100% (61/61), done.\u001b[K\n","remote: Total 707 (delta 31), reused 3 (delta 0), pack-reused 646\u001b[K\n","Receiving objects: 100% (707/707), 37.74 MiB | 27.02 MiB/s, done.\n","Resolving deltas: 100% (113/113), done.\n"]}],"source":["!rm -rf coinrun-game-ai-assignment\n","!git clone https://github.com/markriedl/coinrun-game-ai-assignment.git"]},{"cell_type":"markdown","metadata":{"id":"jLPfDovLRp28"},"source":["Install required packages. The game engine requires a downgrade of numpy, you will have to restart the notebook after this cell completes. You do not need to run the previous cells. You can continue running the next cell after this one."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"hCz2c9bYYNPr","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1712958043580,"user_tz":240,"elapsed":1794701,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"479d5c45-af67-4d34-dfbd-29892ce1f07c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting https://github.com/openai/baselines/archive/7139a66d333b94c2dafc4af35f6a8c7598361df6.zip (from -r coinrun-game-ai-assignment/requirements.txt (line 9))\n","  Downloading https://github.com/openai/baselines/archive/7139a66d333b94c2dafc4af35f6a8c7598361df6.zip\n","\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m4.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting numpy==1.23.5 (from -r coinrun-game-ai-assignment/requirements.txt (line 1))\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow==2.8.0 (from -r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch~=1.8 (from -r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m779.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/torchvision/\u001b[0m\u001b[33m\n","\u001b[0mCollecting torchvision~=0.12.0 (from -r coinrun-game-ai-assignment/requirements.txt (line 4))\n","  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gym~=0.17.1 (from -r coinrun-game-ai-assignment/requirements.txt (line 5))\n","  Downloading gym-0.17.3.tar.gz (1.6 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyglet~=1.5.0 (from -r coinrun-game-ai-assignment/requirements.txt (line 6))\n","  Downloading pyglet-1.5.28-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mpi4py~=3.0 (from -r coinrun-game-ai-assignment/requirements.txt (line 7))\n","  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting joblib~=1.1.1 (from -r coinrun-game-ai-assignment/requirements.txt (line 8))\n","  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m309.8/309.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (24.3.25)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.9.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (4.11.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.14.1)\n","Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.62.1)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch~=1.8->-r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch~=1.8->-r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m962.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch~=1.8->-r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch~=1.8->-r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch~=1.8->-r coinrun-game-ai-assignment/requirements.txt (line 3)) (0.43.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (2.31.0)\n","Collecting torch~=1.8 (from -r coinrun-game-ai-assignment/requirements.txt (line 3))\n","  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym~=0.17.1->-r coinrun-game-ai-assignment/requirements.txt (line 5)) (1.11.4)\n","Collecting pyglet~=1.5.0 (from -r coinrun-game-ai-assignment/requirements.txt (line 6))\n","  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0 (from gym~=0.17.1->-r coinrun-game-ai-assignment/requirements.txt (line 5))\n","  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet~=1.5.0->-r coinrun-game-ai-assignment/requirements.txt (line 6)) (0.18.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9)) (4.66.2)\n","Collecting dill (from baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9))\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: progressbar2 in /usr/local/lib/python3.10/dist-packages (from baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9)) (4.2.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9)) (8.1.7)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9)) (4.8.0.76)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (2.27.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.6)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2))\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision~=0.12.0->-r coinrun-game-ai-assignment/requirements.txt (line 4)) (2024.2.2)\n","Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2->baselines==0.1.5->-r coinrun-game-ai-assignment/requirements.txt (line 9)) (3.8.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0->-r coinrun-game-ai-assignment/requirements.txt (line 2)) (3.2.2)\n","Building wheels for collected packages: gym, mpi4py, baselines\n","  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654618 sha256=1416200121d97325c0087977c9c00ad168afaf2d508ed7d96d1e6fc16bc8b7fd\n","  Stored in directory: /root/.cache/pip/wheels/af/4b/74/fcfc8238472c34d7f96508a63c962ff3ac9485a9a4137afd4e\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp310-cp310-linux_x86_64.whl size=2746525 sha256=17efb7aa99344f05a8d9b0054c7fd094ffb4a9fc9a1c185c018ace6eaba71372\n","  Stored in directory: /root/.cache/pip/wheels/18/2b/7f/c852523089e9182b45fca50ff56f49a51eeb6284fd25a66713\n","  Building wheel for baselines (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for baselines: filename=baselines-0.1.5-py3-none-any.whl size=210121 sha256=ec4fffe220c99c0f9c91c64025b11c93341ae67035f5931aead56e97adf20442\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ualg06sa/wheels/64/71/d0/08b826a130fa20d9d809f8f3ab11153cac7d95d142d2137cf6\n","Successfully built gym mpi4py baselines\n","Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, torch, tensorboard-data-server, pyglet, numpy, mpi4py, joblib, dill, cloudpickle, torchvision, keras-preprocessing, gym, google-auth-oauthlib, tensorboard, baselines, tensorflow\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.1+cu121\n","    Uninstalling torch-2.2.1+cu121:\n","      Successfully uninstalled torch-2.2.1+cu121\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.4.0\n","    Uninstalling joblib-1.4.0:\n","      Successfully uninstalled joblib-1.4.0\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 2.2.1\n","    Uninstalling cloudpickle-2.2.1:\n","      Successfully uninstalled cloudpickle-2.2.1\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.17.1+cu121\n","    Uninstalling torchvision-0.17.1+cu121:\n","      Successfully uninstalled torchvision-0.17.1+cu121\n","  Attempting uninstall: gym\n","    Found existing installation: gym 0.25.2\n","    Uninstalling gym-0.25.2:\n","      Successfully uninstalled gym-0.25.2\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 1.0.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.0 which is incompatible.\n","torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.11.0 which is incompatible.\n","torchdata 0.7.1 requires torch>=2, but you have torch 1.11.0 which is incompatible.\n","torchtext 0.17.1 requires torch==2.2.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed baselines-0.1.5 cloudpickle-1.6.0 dill-0.3.8 google-auth-oauthlib-0.4.6 gym-0.17.3 joblib-1.1.1 keras-2.8.0 keras-preprocessing-1.1.2 mpi4py-3.1.5 numpy-1.23.5 pyglet-1.5.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.11.0 torchvision-0.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"8c9e3eee0dec4f209b8ef31e67b6fca1"}},"metadata":{}}],"source":["!pip install -r coinrun-game-ai-assignment/requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"Ec4qM9WOSCcW"},"source":["Set up path requirements so the rest of the code can find the game engine."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-MBLQF6MYUw0","executionInfo":{"status":"ok","timestamp":1712958163484,"user_tz":240,"elapsed":104,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["import sys\n","sys.path.insert(0, 'coinrun-game-ai-assignment')"]},{"cell_type":"markdown","metadata":{"id":"otukTgSQSI4O"},"source":["Import torch and make sure the GPU is available."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2231,"status":"ok","timestamp":1712958167123,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"},"user_tz":240},"id":"FW2gBefjYZU1","outputId":"d6d7e49a-7094-4b2b-d60c-14760a2ab24c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["import torch\n","torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"SzI7EuW1C4Dj"},"source":["If the prior cell repots ```False```, then use notebooks settings to turn GPU support on."]},{"cell_type":"markdown","metadata":{"id":"wIaY3PFJSkh3"},"source":["Test to make sure the game engine installed correctly. This loads the game engine and runs a random agent for 10 steps. The first time you run this it will be slow because there is some C++ code that must be compiled."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"rg9yJt6MYhJl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712958218561,"user_tz":240,"elapsed":1680,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"716fe17b-5257-447e-e349-86f3e0c1f975"},"outputs":[{"output_type":"stream","name":"stdout","text":["step 0 rews [0.]\n","step 1 rews [0.]\n","step 2 rews [0.]\n","step 3 rews [0.]\n","step 4 rews [0.]\n","step 5 rews [0.]\n","step 6 rews [0.]\n","step 7 rews [0.]\n","step 8 rews [0.]\n","step 9 rews [0.]\n"]}],"source":["# THIS TESTS THE COINRUN INSTALLATION\n","from coinrun.random_agent import random_agent\n","\n","random_agent(max_steps=10)"]},{"cell_type":"markdown","metadata":{"id":"YJgvgUwlQ733"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"S9xQQxXwSxOn"},"source":["This checks to see if the game engine is inside an ipython notebook environment."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"rOihwhu6QDsA","executionInfo":{"status":"ok","timestamp":1712958221639,"user_tz":240,"elapsed":97,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### RUN THIS BUT DO NOT EDIT THIS CELL\n","def in_ipynb():\n","  try:\n","    result = get_ipython().__class__.__name__\n","    if 'Shell' in result:\n","      return True\n","    else:\n","      return False\n","  except:\n","    return False\n","\n","IN_PYNB = in_ipynb()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k3zNCwKHS_ii"},"source":["Import required pacakges"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"w8I-vSF8QBud","executionInfo":{"status":"ok","timestamp":1712958227524,"user_tz":240,"elapsed":4652,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### RUN THIS BUT DO NOT EDIT THIS CELL\n","import gym\n","import os\n","import math\n","import random\n","import numpy as np\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","\n","from coinrun import setup_utils, make\n","import coinrun.main_utils as utils\n","from coinrun.config import Config\n","if not IN_PYNB:\n","    from gym.envs.classic_control import rendering\n","from coinrun import policies, wrappers\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","import pdb"]},{"cell_type":"markdown","metadata":{"id":"S2BIgnSptQHk"},"source":["This will save to a new directory in \"cache\" named for the run_num.\n","\n","Filename is eval + screen_count + .jpeg\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"xyDaJjW_tJxb","executionInfo":{"status":"ok","timestamp":1712958230074,"user_tz":240,"elapsed":85,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["RUN_NUM = 0\n","SCREEN_SAVE = False\n","SCREEN_COUNT = 0\n","SCREEN_SAVE_PREFIX = 'eval'\n","SCREEN_SAVE_POSTFIX = '.jpeg'\n","TEMP_DIR = 'cache'\n","SCREEN_SAVE_RATIO = 0.5\n","\n","#Screen is numpy array\n","def save_screen(screen):\n","  global SCREEN_COUNT\n","  screen_array_t = np.transpose(screen, (1, 2, 0))\n","  img = Image.fromarray(np.uint8(screen_array_t * 255))\n","  width, height = img.size\n","  img = img.resize((int(width*SCREEN_SAVE_RATIO), int(height*SCREEN_SAVE_RATIO)), Image.LANCZOS)\n","  if not os.path.isdir(TEMP_DIR):\n","    os.mkdir(TEMP_DIR)\n","  if not os.path.isdir(os.path.join(TEMP_DIR, str(RUN_NUM))):\n","    os.mkdir(os.path.join(TEMP_DIR, str(RUN_NUM)))\n","  img.save(os.path.join(TEMP_DIR, str(RUN_NUM), SCREEN_SAVE_PREFIX + str(SCREEN_COUNT) + SCREEN_SAVE_POSTFIX), \"JPEG\")\n","  SCREEN_COUNT = SCREEN_COUNT + 1"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"9VMXBwxYmpYT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712958232103,"user_tz":240,"elapsed":118,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"75ab191c-1aa3-46c4-928e-448b16b85e6b"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-88b0f302ef7d>:39: DeprecationWarning: CUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use BICUBIC or Resampling.BICUBIC instead.\n","  T.Resize(RESIZE_CONST, interpolation=Image.CUBIC),\n","/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  warnings.warn(\n"]}],"source":["### RUN THIS BUT DO NOT EDIT THIS CELL\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Resize the screen to this\n","RESIZE_CONST = 40\n","\n","\n","# Game seed information\n","NUM_LEVELS = 1 # repeat the same level over and over\n","EASY_LEVEL = 1 # Start on a very small map, no enemies\n","EASY_LEVEL2 = 5 # Very small map, no enemies\n","MEDIUM_LEVEL = 20 # Medium length, no enemies\n","MEDIUM_LEVEL2 = 45 # Medium length, no enemies\n","ONE_MONSTER = 10 # Short map with one monster\n","HARD_LEVEL = 7 # Longer and with monsters\n","LAVA_LEVEL = 3 # Longer and with lava and pits\n","\n","# Defaults\n","RENDER_SCREEN = False\n","SAVE_FILENAME = 'saved.model'\n","LOAD_FILENAME = 'saved.model'\n","MODEL_PATH = 'saved_models'\n","SEED = EASY_LEVEL\n","\n","# Don't play with this\n","EVAL_EPSILON = 0.1\n","EVAL_WINDOW_SIZE = 3\n","EVAL_COUNT = 5\n","TIMEOUT = 1000\n","COIN_REWARD = 100\n","\n","### Data structure for holding experiences for replay\n","Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","### Function for resizing the screen\n","resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(RESIZE_CONST, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","### Save the model. Extra information can be added to the end of the filename\n","def save_model(model, filename, extras = None):\n","    if extras is not None:\n","        filename = filename + '.' + str(extras)\n","    print(\"Saving\", filename, \"...\")\n","    torch.save(model, os.path.join(MODEL_PATH, filename))\n","    print(\"Done saving.\")\n","\n","### Load the model. If there are multiple versions with extra information at the\n","### end of the filename, get the latest.\n","def load_model(filename, extras = None):\n","    if extras is not None:\n","        filename = filename + '.' + str(extras)\n","    model = None\n","    candidates = [os.path.join(MODEL_PATH, f) for f in os.listdir(MODEL_PATH) if filename in f]\n","    if len(candidates) > 0:\n","        candidates = sorted(candidates, key=lambda f:os.stat(f).st_mtime, reverse=True)\n","        filename = candidates[0]\n","        print(\"Loading\", filename, \"...\")\n","        model = torch.load(filename)\n","        print(\"Done loading.\")\n","    return model\n","\n","### Give a text description of the outcome of an episode and also a score\n","### Score is duration, unless the agent died.\n","def episode_status(duration, reward):\n","    status = \"\"\n","    score = 0\n","    if duration >= TIMEOUT:\n","        status = \"timeout\"\n","        score = duration\n","    elif reward < COIN_REWARD:\n","        status = \"died\"\n","        score = TIMEOUT\n","    else:\n","        status = \"coin\"\n","        score = duration\n","    return status, score"]},{"cell_type":"markdown","metadata":{"id":"sDC4SQYzRAY8"},"source":["# Globals"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"B930j8EMQq2l","executionInfo":{"status":"ok","timestamp":1712958234918,"user_tz":240,"elapsed":100,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["# YOU MAY EDIT THESE IF NECESSARY\n","\n","BATCH_SIZE = 128            # How many replay experiences to run through neural net at once\n","GAMMA = 0.999               # How much to discount the future [0..1]\n","BOOTSTRAP = 10000           # How many steps to run to fill up replay memory before training starts\n","TARGET_UPDATE = 0           # Delays updating the network for loss calculations. 0=don't delay, or 1+ number of episodes\n","REPLAY_CAPACITY = 10000     # How big is the replay memory\n","EPSILON = 0.9             # Use random action if less than epsilon [0..1]\n","EVAL_INTERVAL = 10          # How many episodes of training before evaluation\n","NUM_EPISODES = 500          # Max number of training episodes\n","RANDOM_SEED = None          # Seed for random number generator, for reproducability, use None for random seed"]},{"cell_type":"markdown","metadata":{"id":"UGXg2Wp0Q2m5"},"source":["# Reference Functions\n","\n","Run these cells but do not edit them."]},{"cell_type":"markdown","metadata":{"id":"WcBRVLjwUIl6"},"source":["## Unit Testing Functions"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Y_McIDrJPgnT","executionInfo":{"status":"ok","timestamp":1712958236511,"user_tz":240,"elapsed":125,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["# RUN THIS CELL BUT DO NOT EDIT.\n","\n","def testReplayMemory():\n","    print(\"Testing ReplayMemory...\")\n","    capacity = 100\n","    test_replay_memory = ReplayMemory(capacity)\n","    for i in range(capacity):\n","        test_replay_memory.push(i, i, i, i)\n","    assert (len(test_replay_memory) == capacity),\"size test failed\"\n","    for i in range(len(test_replay_memory)):\n","        item = test_replay_memory.memory[i]\n","        assert (item[0] == i), \"item\" + str(i) + \"not holding the correct value\"\n","    for i in range(capacity//2):\n","        test_replay_memory.push(capacity+i, capacity+i, capacity+i, capacity+i)\n","    assert (len(test_replay_memory) == capacity), \"size test 2 failed\"\n","    # check items\n","    for i in range(len(test_replay_memory)):\n","        item = test_replay_memory.memory[i]\n","        if i < capacity // 2:\n","            assert (item[0] == i+capacity), \"not holding the correct value after looping (first half)\"\n","        else:\n","            assert (item[0] == i), \"not holding the correct value after looping (second half)\"\n","    print(\"ReplayMemory test passed.\")\n","    return True\n","\n","def testMakeBatch():\n","    print(\"Testing doMakeBatch...\")\n","    batch_size = 128\n","    capacity = batch_size * 2\n","    test_replay_memory = ReplayMemory(capacity)\n","    state = None\n","    new_state = None\n","    action = None\n","    reward = None\n","    # Test types and shapes of return values\n","    for i in range(capacity):\n","        state = torch.randn(1, 3, 80, 80, device=DEVICE)\n","        new_state = torch.randn(1, 3, 80, 80, device=DEVICE)\n","        action = torch.randn(1, 1, device=DEVICE)\n","        reward = torch.randn(1, 1, device=DEVICE)\n","        test_replay_memory.push(state, action, new_state, reward)\n","    states_batch, actions_batch, next_states_batch, rewards_batch, non_final_mask = doMakeBatch(test_replay_memory, batch_size)\n","    assert(type(states_batch) == torch.Tensor and states_batch.size() == (batch_size, 3, 80, 80)), \"states batch not correct shape.\"\n","    assert(type(actions_batch) == torch.Tensor and actions_batch.size() == (batch_size, 1)), \"actions batch not correct shape.\"\n","    assert(type(next_states_batch) == torch.Tensor and next_states_batch.size() == (batch_size, 3, 80, 80)), \"next states batch not correct shape.\"\n","    assert(type(rewards_batch) == torch.Tensor and rewards_batch.size() == (batch_size, 1)), \"rewards batch not correct shape.\"\n","    assert(type(non_final_mask) == type(torch.tensor(batch_size, dtype=torch.bool, device=DEVICE)) and non_final_mask.size()[0] == batch_size), \"non-final mask not correct shape.\"\n","\n","    # Test mask\n","    test_replay_memory = ReplayMemory(batch_size)\n","    for i in range(batch_size):\n","        state = torch.randn(1, 3, 80, 80, device=DEVICE)\n","        new_state = None\n","        if i % 2 == 0:\n","            new_state = torch.randn(1, 3, 80, 80, device=DEVICE)\n","        action = torch.randn(1, 1, device=DEVICE)\n","        reward = torch.randn(1, 1, device=DEVICE)\n","        test_replay_memory.push(state, action, new_state, reward)\n","    states_batch, actions_batch, next_states_batch, rewards_batch, non_final_mask = doMakeBatch(test_replay_memory, batch_size)\n","    assert(non_final_mask.sum() == batch_size//2), \"non_final_mask not masking properly.\"\n","    print(\"doMakeBatch test passed.\")\n","    return True\n","\n","class UnitTestDQN(nn.Module):\n","    def __init__(self, h, w, num_actions):\n","        super(UnitTestDQN, self).__init__()\n","        self.num_actions = num_actions\n","    def forward(self, x):\n","        assert(False), \"Network should not be queried when epsilon = 1.0.\"\n","        return None\n","\n","def testSelectAction():\n","    print(\"Testing select_action...\")\n","    from scipy.stats import chisquare\n","    sample_size = 10000\n","    num_tests = 100\n","    pass_rate = 0.9\n","    screen_height = 40\n","    screen_width = 40\n","    epsilon = 1.0\n","    num_actions = 7\n","    test_results = {True: 0, False: 0}\n","    significance_level = 0.02\n","    net = UnitTestDQN(screen_height, screen_width, num_actions).to(DEVICE)\n","    state = torch.randn(1, 3, 80, 80, device=DEVICE)\n","    for j in range(num_tests):\n","        samples = {}\n","        for i in range(sample_size):\n","            action, new_epsilon = select_action(state, net, num_actions, epsilon, steps_done = 0, bootstrap_threshold = 2)\n","            assert(type(action) == torch.Tensor and action.size() == (1,1)), \"Action not correct shape.\"\n","            assert(new_epsilon == epsilon), \"Epsilon should not change during bootstrapping.\"\n","            action = action.item()\n","            if action not in samples:\n","                samples[action] = 0\n","            samples[action] = samples[action] + 1\n","        expected = [sample_size / num_actions] * num_actions\n","        statistic, pvalue = chisquare(f_obs=list(samples.values()), f_exp=expected)\n","        test_results[pvalue >= significance_level] += 1\n","    assert(test_results[True] > pass_rate * num_tests), \"Random sample is not from uniform distribution.\"\n","    print(\"select_action test passed.\")\n","    return True\n","\n","def testPredictQValues():\n","    print(\"Testing doPredictQValues...\")\n","    batch_size = 128\n","    screen_height = 80\n","    screen_width = 80\n","    num_actions = 7\n","    net = DQN(screen_height, screen_width, num_actions).to(DEVICE)\n","    states_batch = torch.randn(batch_size, 3, 80, 80, device=DEVICE)\n","    actions_batch = torch.randint(0, 7, (128, 1), device=DEVICE).long()\n","    state_action_values = doPredictQValues(net, states_batch, actions_batch)\n","    assert(type(state_action_values) == torch.Tensor and state_action_values.size() == (128, 1)), \"Return value not correct shape.\"\n","    print(\"doPredictQValues test passed.\")\n","    return True\n","\n","def testPredictNextStateUtilities():\n","    print(\"Testing doPredictNextStateUtilities...\")\n","    screen_height = 80\n","    screen_width = 80\n","    num_actions = 7\n","    batch_size = 128\n","    passed = False\n","    net = DQN(screen_height, screen_width, num_actions).to(DEVICE)\n","    # First option to try is that the batch is full sized.\n","    try:\n","        next_states_batch = torch.ones(batch_size, 3, 80, 80, device=DEVICE)\n","        non_final_mask = torch.ones(batch_size, dtype=torch.bool, device=DEVICE)\n","        for i in range(batch_size):\n","            if i % 2 == 1:\n","                next_states_batch[i].fill_(0)\n","                non_final_mask[i] = 0\n","        next_state_values = doPredictNextStateUtilities(net, next_states_batch, non_final_mask, batch_size)\n","        assert(type(next_state_values) == torch.Tensor and next_state_values.size() == (batch_size, 1)), \"Return value not correct shape (attempt 1).\"\n","        for i in range(batch_size):\n","            if i % 2 == 1:\n","                assert(next_state_values[i].sum() == 0), \"Element \" + str(i) + \"is not 0.0 when non_final_mask[i] = 0\"\n","        passed = True\n","    except RuntimeError as e:\n","        print(e)\n","        print(\"Will try alternative test.\")\n","    if not passed:\n","        # Next option is that batch is not full sized.\n","        try:\n","            next_states_batch = torch.ones(batch_size-1, 3, 80, 80, device=DEVICE)\n","            non_final_mask = torch.ones(batch_size, dtype=torch.bool, device=DEVICE)\n","            non_final_mask[0] = 0\n","            next_state_values = doPredictNextStateUtilities(net, next_states_batch, non_final_mask, batch_size)\n","            assert(type(next_state_values) == torch.Tensor and next_state_values.size() == (batch_size, 1)), \"Return value not correctd shape (attempt 2).\"\n","            passed = True\n","        except RuntimeError as e:\n","            print(e)\n","            print(\"No further alternative tests available.\")\n","    if passed:\n","        print(\"doPredictNextStateUtilities test passed.\")\n","        return True\n","    assert(False), \"doPredictNextStateUtilities did NOT pass test.\"\n","\n","def testComputeExpectedQValues():\n","    print(\"Testing doComputeExpectedQValues...\")\n","    batch_size = 128\n","    gamma = 0.5\n","    next_state_values = torch.ones(batch_size).unsqueeze(1)\n","    rewards_batch = torch.ones(batch_size).unsqueeze(1)\n","    expected_state_action_values = doComputeExpectedQValues(next_state_values, rewards_batch, gamma)\n","    assert(type(expected_state_action_values) == torch.Tensor and expected_state_action_values.size()[0] == batch_size), \"Return value not expected shape.\"\n","    for i in range(batch_size):\n","        assert(expected_state_action_values[i].item() == 1.5), \"Element \" + str(i) + \" doesn't have the correct value.\"\n","    print(\"doComputeExpectedQValues test passed.\")\n","    return True\n","\n","def testComputeLoss():\n","    print(\"Testing doComputeLoss...\")\n","    batch_size = 128\n","    state_action_values = torch.randn(batch_size, device=DEVICE)\n","    expected_state_action_values = torch.randn(batch_size, device=DEVICE)\n","    loss = doComputeLoss(state_action_values, expected_state_action_values)\n","    assert(type(loss) == torch.Tensor and len(loss.size()) == 0), \"Loss not of expected shape.\"\n","    print(\"doComputeLoss test passed.\")\n","    return True\n","\n","\n","def unit_test():\n","    testReplayMemory()\n","    testMakeBatch()\n","    #testSelectAction()\n","    testPredictQValues()\n","    testPredictNextStateUtilities()\n","    testComputeExpectedQValues()\n","    testComputeLoss()"]},{"cell_type":"markdown","metadata":{"id":"kpQNNe2yUN_d"},"source":["## Training loop"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"nPuXQWPDQTem","executionInfo":{"status":"ok","timestamp":1712958241226,"user_tz":240,"elapsed":90,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["# RUN THIS CELL BUT DO NOT EDIT.\n","\n","### Training loop.\n","### Each episode is a game that runs until the agent gets the coin or the game times out.\n","### Train for a given number of episodes.\n","def train(num_episodes = NUM_EPISODES, load_filename = None, save_filename = None, eval_interval = EVAL_INTERVAL, replay_capacity = REPLAY_CAPACITY, bootstrap_threshold = BOOTSTRAP, epsilon = EPSILON, eval_epsilon = EVAL_EPSILON, gamma = GAMMA, batch_size = BATCH_SIZE, target_update = TARGET_UPDATE, random_seed = RANDOM_SEED, num_levels = NUM_LEVELS, seed = SEED):\n","    # Set the random seed\n","    if random_seed is not None:\n","        random.seed(random_seed)\n","        torch.manual_seed(random_seed)\n","        if torch.cuda.is_available():\n","            torch.cuda.manual_seed_all(RANDOM_SEED)\n","    # Set up the environment\n","    setup_utils.setup_and_load(use_cmd_line_args=False, is_high_res=True, num_levels=num_levels, set_seed=seed)\n","    env = make('standard', num_envs=1)\n","    if RENDER_SCREEN and not IN_PYNB:\n","        env.render()\n","\n","    # Reset the environment\n","    env.reset()\n","\n","    # Get screen size so that we can initialize layers correctly based on shape returned from AI gym.\n","    init_screen = get_screen(env)\n","    _, _, screen_height, screen_width = init_screen.shape\n","    print(\"screen size: \", screen_height, screen_width)\n","\n","    # Are we resuming from an existing model?\n","    policy_net = None\n","    if load_filename is not None and os.path.isfile(os.path.join(MODEL_PATH, load_filename)):\n","        print(\"Loading model...\")\n","        policy_net = load_model(load_filename)\n","        policy_net = policy_net.to(DEVICE)\n","        print(\"Done loading.\")\n","    else:\n","        print(\"Making new model.\")\n","        policy_net = DQN(screen_height, screen_width, env.NUM_ACTIONS).to(DEVICE)\n","    # Make a copy of the policy network for evaluation purposes\n","    eval_net = DQN(screen_height, screen_width, env.NUM_ACTIONS).to(DEVICE)\n","    eval_net.load_state_dict(policy_net.state_dict())\n","    eval_net.eval()\n","    # Target network is a snapshot of the policy network that lags behind (for stablity)\n","    target_net = DQN(screen_height, screen_width, env.NUM_ACTIONS).to(DEVICE)\n","    target_net.load_state_dict(policy_net.state_dict())\n","    target_net.eval()\n","\n","    # Instantiate the optimizer\n","    optimizer = None\n","    if len(list(policy_net.parameters())) > 0:\n","        optimizer = initializeOptimizer(policy_net.parameters())\n","\n","    # Instantiate the replay memory\n","    replay_memory = ReplayMemory(replay_capacity)\n","\n","    steps_done = 0               # How many steps have been run\n","    best_eval = float('inf')     # The best model evaluation to date\n","\n","    ### Do training until episodes complete\n","    print(\"training...\")\n","    i_episode = 0            # The episode number\n","\n","    # Stop when we reach max episodes\n","    while i_episode < num_episodes:\n","        print(\"episode:\", i_episode, \"epsilon:\", epsilon)\n","        max_reward = 0       # The best reward we've seen this episode\n","        done = False         # Has the game ended (timed out or got the coin)\n","        episode_steps = 0    # Number of steps performed in this episode\n","        # Initialize the environment and state\n","        env.reset()\n","\n","        # Current screen. There is no last screen because we get velocity on the screen itself.\n","        state = get_screen(env)\n","\n","        # Do forever until the loop breaks\n","        while not done:\n","            # Select and perform an action\n","            action, epsilon = select_action(state, policy_net, env.NUM_ACTIONS, epsilon, steps_done, bootstrap_threshold)\n","            steps_done = steps_done + 1\n","            episode_steps = episode_steps + 1\n","\n","            # for debugging\n","            if RENDER_SCREEN and not IN_PYNB:\n","                env.render()\n","\n","            # Run the action in the environment\n","            if action is not None:\n","                _, reward, done, _ = env.step(np.array([action.item()]))\n","\n","                # Record if this was the best reward we've seen so far\n","                max_reward = max(reward, max_reward)\n","\n","                # Turn the reward into a tensor\n","                reward = torch.tensor([reward], device=DEVICE)\n","\n","                # Observe new state\n","                current_screen = get_screen(env)\n","\n","                # Did the game end?\n","                if not done:\n","                    next_state = current_screen\n","                else:\n","                    next_state = None\n","\n","                # Store the transition in memory\n","                replay_memory.push(state, action, next_state, reward)\n","\n","                # Move to the next state\n","                state = next_state\n","\n","                # If we are past bootstrapping we should perform one step of the optimization\n","                if steps_done > bootstrap_threshold:\n","                  optimize_model(policy_net, target_net if target_update > 0 else policy_net, replay_memory, optimizer, batch_size, gamma)\n","            else:\n","                # Do nothing if select_action() is not implemented and returning None\n","                env.step(np.array([0]))\n","\n","            # If we are done, print some statistics\n","            if done:\n","                print(\"duration:\", episode_steps)\n","                print(\"max reward:\", max_reward)\n","                status, _ = episode_status(episode_steps, max_reward)\n","                print(\"result:\", status)\n","                print(\"total steps:\", steps_done, '\\n')\n","\n","            # Should we update the target network?\n","            if target_update > 0 and i_episode % target_update == 0:\n","                target_net.load_state_dict(policy_net.state_dict())\n","\n","        # Should we evaluate?\n","        if steps_done > bootstrap_threshold and i_episode > 0 and i_episode % eval_interval == 0:\n","            test_average_duration = 0       # Track the average eval duration\n","            test_average_max_reward = 0     # Track the average max reward\n","            # copy all the weights into the evaluation network\n","            eval_net.load_state_dict(policy_net.state_dict())\n","            # Evaluate 10 times\n","            for _ in range(EVAL_COUNT):\n","                # Call the evaluation function\n","                test_duration, test_max_reward = evaluate(eval_net, eval_epsilon, env, test_seed=seed)\n","                status, score = episode_status(test_duration, test_max_reward)\n","                test_duration = score # Set test_duration to score to factor in death-penalty\n","                test_average_duration = test_average_duration + test_duration\n","                test_average_max_reward = test_average_max_reward + test_max_reward\n","            test_average_duration = test_average_duration / EVAL_COUNT\n","            test_average_max_reward = test_average_max_reward / EVAL_COUNT\n","            print(\"Average duration:\", test_average_duration)\n","            print(\"Average max reward:\", test_average_max_reward)\n","            # If this is the best window average we've seen, save the model\n","            if test_average_duration < best_eval:\n","                best_eval = test_average_duration\n","                if save_filename is not None:\n","                    save_model(policy_net, save_filename, i_episode)\n","            print(' ')\n","        # Only increment episode number if we are done with bootstrapping\n","        if steps_done > bootstrap_threshold:\n","          i_episode = i_episode + 1\n","    print('Training complete')\n","    if RENDER_SCREEN and not IN_PYNB:\n","        env.render()\n","    env.close()\n","    return policy_net"]},{"cell_type":"markdown","metadata":{"id":"nCkpDANAURJT"},"source":["\n","## Optimization Function\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"7l6qXukQUVyk","executionInfo":{"status":"ok","timestamp":1712958246038,"user_tz":240,"elapsed":157,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["# RUN THIS CELL BUT DO NOT EDIT.\n","\n","### Take a DQN and do one forward-backward pass.\n","### Since this is Q-learning, we will run a forward pass to get Q-values for state-action pairs and then\n","### give the true value as the Q-values after the Q-update equation.\n","def optimize_model(policy_net, target_net, replay_memory, optimizer, batch_size, gamma):\n","    if len(replay_memory) < batch_size:\n","        return\n","    ### step 1: sample from the replay memory. Get BATCH_SIZE transitions\n","    ### Step 2: Get a list of non-final next states.\n","    ###         a. Create a mask, a tensor of length BATCH_SIZE where each element i is 1 if\n","    ###            batch.next_state[i] is not None and 0 otherwise.\n","    ###         b. Create a tensor of shape [BATCH_SIZE, color(3), height, width] by concatenating\n","    ###            all non-final (not None) batch.next_states together.\n","    ### Step 3: set up batches for state, action, and reward\n","    ###         a. Create a tensor of shape [BATCH_SIZE, color(3), height, width] holding states\n","    ###         b. Create a tensor of shape [BATCH_SIZE, 1] holding actions\n","    ###         c. Create a tensor of shape [BATCH_SIZE, 1] holding rewards\n","    states_batch, actions_batch, next_states_batch, rewards_batch, non_final_mask = doMakeBatch(replay_memory, batch_size)\n","\n","    ### Step 4: Get the action values predicted.\n","    ###         a. Call policy_net(state_batch) to get a tensor of shape [BATCH_SIZE, NUM_ACTIONS] containing Q-values\n","    ###         b. For each batch, get the Q-value for the corresponding action in action_batch (hint: torch.gather)\n","    state_action_values = doPredictQValues(policy_net, states_batch, actions_batch)\n","\n","    ### Step 5: Get the utility values of next_states.\n","    next_state_values = doPredictNextStateUtilities(target_net, next_states_batch, non_final_mask, batch_size)\n","\n","    ### Step 6: Compute the expected Q values.\n","    expected_state_action_values = doComputeExpectedQValues(next_state_values, rewards_batch, gamma)\n","\n","    ### Step 7: Computer Huber loss (smooth L1 loss)\n","    ###         Compare state action values from step 5 to expected state action values from step 7\n","    loss = doComputeLoss(state_action_values, expected_state_action_values)\n","    ### Step 8: Back propagation\n","    ###         a. Zero out gradients\n","    ###         b. call loss.backward()\n","    ###         c. Prevent gradient explosion by clipping gradients between -1 and 1\n","    ###            (hint: param.grad.data is the gradients. See torch.clamp_() )\n","    ###         d. Tell the optimizer that another step has occurred: optimizer.step()\n","    if optimizer is not None:\n","        optimizer.zero_grad()\n","        doBackprop(loss, policy_net.parameters())\n","        optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"fXuPMZw7UZla"},"source":["## Evaluation function"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"DGy1g-scUbX3","executionInfo":{"status":"ok","timestamp":1712958247733,"user_tz":240,"elapsed":2,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["# RUN THIS CELL BUT DO NOT EDIT.\n","\n","### Evaluate the DQN\n","### If environment is given, use that. Otherwise make a new environment.\n","def evaluate(policy_net, epsilon = EVAL_EPSILON, env = None, test_seed = SEED):\n","    global RUN_NUM\n","    RUN_NUM = RUN_NUM + 1\n","    setup_utils.setup_and_load(use_cmd_line_args=False, is_high_res=True, num_levels=NUM_LEVELS, set_seed=test_seed)\n","\n","\n","    # Make an environment if we don't already have one\n","    if env is None:\n","        env = make('standard', num_envs=1)\n","    if RENDER_SCREEN and not IN_PYNB:\n","        env.render()\n","\n","    # Reset the environment\n","    env.reset()\n","\n","    # Get screen size so that we can initialize layers correctly based on shape\n","    # returned from AI gym.\n","    init_screen = get_screen(env, SCREEN_SAVE)\n","    _, _, screen_height, screen_width = init_screen.shape\n","\n","    # Get the network ready for evaluation (turns off some things like dropout if used)\n","    policy_net.eval()\n","\n","    # Current screen. There is no last screen\n","    state = get_screen(env, SCREEN_SAVE)\n","\n","    steps_done = 0         # Number of steps executed\n","    max_reward = 0         # Max reward seen\n","    done = False           # Is the game over?\n","\n","    print(\"Evaluating...\")\n","    while not done:\n","        # Select and perform an action\n","        action, _ = select_action(state, policy_net, env.NUM_ACTIONS, epsilon, steps_done=0, bootstrap_threshold=0)\n","        steps_done = steps_done + 1\n","\n","        if RENDER_SCREEN and not IN_PYNB:\n","            env.render()\n","\n","        # Execute the action\n","        if action is not None:\n","            _, reward, done, _ = env.step(np.array([action.item()]))\n","\n","            # Is this the best reward we've seen?\n","            max_reward = max(reward, max_reward)\n","\n","            # Observe new state\n","            state = get_screen(env, SCREEN_SAVE)\n","        else:\n","            # Do nothing if select_action() is not implemented and returning None\n","            env.step(np.array([0]))\n","\n","    print(\"duration:\", steps_done)\n","    print(\"max reward:\", max_reward)\n","    status, _ = episode_status(steps_done, max_reward)\n","    print(\"result:\", status, '\\n')\n","    if RENDER_SCREEN and not IN_PYNB:\n","        env.render()\n","    return steps_done, max_reward\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0qW_WqgyDPkT"},"source":["# Your Implementation"]},{"cell_type":"markdown","metadata":{"id":"TVXdyG9ZRfnu"},"source":["## DQN"]},{"cell_type":"markdown","metadata":{"id":"oq_2eJL6TbvL"},"source":["**Complete the DQN class definition.** You should implement a convolutional neural network that feeds into a multilayer feed forward network. The input will be a batch of screen of size `batch_size x 3 x h x w` and with three color channels. The output should be a linear array of q-values of length `num_actions`. You do not need to create the batches yourself (that will be done elsewhere), but your forward function should operate with both single screens (batch size 1) and with full batches.\n","\n","Types of layers that you might find valuable:\n","\n","* ```nn.Conv2d```: Creates a 2D convoluational layer.\n","* ```nn.BatchNorm2d```: Makes training more stable. See this [explanation](http://mlexplained.com/2018/01/10/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1/).\n","* ```nn.ReLU```: a rectified linear unit ```y = x if x >= 0 else 0```\n","* ```nn.LeakyReLU```: a rectified linear unit that allows a small negative value if the input is less than 0.\n","* ```nn.Linear```: map a layer of size ```l_in``` to a layer of size ```l_out```. Typically used in conjunction with activation functions such as ReLU, except for the final layer."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"r3SKJfm-Ek6Z","executionInfo":{"status":"ok","timestamp":1712958982456,"user_tz":240,"elapsed":124,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["def get_conv_op(x, k, s, p=0):\n","    return int((x - k + 2 * p) / s) + 1\n","\n","\n","class DQN(nn.Module):\n","\n","\n","    ### Create all the nodes in the computation graph.\n","    ### We won't say how to put the nodes together into a computation graph. That is done\n","    ### automatically when forward() is called.\n","    def __init__(self, h, w, num_actions):\n","        super(DQN, self).__init__()\n","        self.num_actions = num_actions\n","\n","        ### WRITE YOUR CODE BELOW HERE\n","\n","        self.height = h\n","        self.width = w\n","\n","        k1,s1,c1 = 3,3,3\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=c1, kernel_size=k1, stride=s1),\n","            nn.ReLU()\n","        )\n","\n","        h1 = get_conv_op(h,k1,s1)\n","        w1 = get_conv_op(w,k1,s1)\n","\n","        k2,s2,c2 = 3,2,3\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(in_channels=c1, out_channels=c2, kernel_size=k2, stride=s2),\n","            nn.ReLU()\n","        )\n","\n","        h2 = get_conv_op(h1,k2,s2)\n","        w2 = get_conv_op(w1,k2,s2)\n","\n","        inter_f = 100\n","\n","        self.layer3 = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(c2*h2*w2, inter_f),\n","            nn.Linear(inter_f, self.num_actions)\n","        )\n","        ### WRITE YOUR CODE ABOVE HERE\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","    def forward(self, x):\n","        q_values = None\n","        ### WRITE YOUR CODE BELOW HERE\n","        op1 = self.layer1(x)\n","        op2 = self.layer2(op1)\n","        q_values = self.layer3(op2)\n","        ### WRITE YOUR CODE ABOVE HERE\n","        return q_values"]},{"cell_type":"markdown","metadata":{"id":"FNKfO3pQRlrx"},"source":["## get_screen"]},{"cell_type":"markdown","metadata":{"id":"6KXNSSs3T7ei"},"source":["You may choose to manipulate the raw pixels of the screen before sending that information into the DQN, for eample making the screen grayscale. This is probably not necessary, but the option is available."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Z3RlDdQigCx0","executionInfo":{"status":"ok","timestamp":1712958253059,"user_tz":240,"elapsed":81,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Take the environment and return a tensor containing screen data as a 3D tensor containing (color, height, width) information.\n","### Optional: the screen may be manipulated, for example, it could be cropped\n","def get_screen(env, save = False):\n","    # Returned screen requested by gym is 512x512x3. Transpose it into torch order (Color, Height, Width).\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    _, screen_height, screen_width = screen.shape\n","    ### DO ANY SCREEN MANIPULATIONS NECESSARY (IF ANY)\n","\n","    ### END SCREEN MANIPULATIONS\n","    # Convert to float, rescale, convert to torch tensor\n","    # (this doesn't require a copy)\n","    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n","    if save:\n","      save_screen(screen)\n","    screen = torch.from_numpy(screen)\n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0).to(DEVICE)"]},{"cell_type":"markdown","metadata":{"id":"ospeXs0qRppd"},"source":["## ReplayMemory"]},{"cell_type":"markdown","metadata":{"id":"0qlpGKO6UKGW"},"source":["**Complete the `push()` function.**\n","The Replay Memory implements a ring buffer. The `memory` member will be an array of tuples of type `Transition`. The capacity is the number of elements that memory can hold. The `position` is the index of the next memory to be inserted into memory. Make sure to increment `position` after every push and to reset it to 0 when it reaches capacity."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"YqLyc5EggFeT","executionInfo":{"status":"ok","timestamp":1712958254439,"user_tz":240,"elapsed":87,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Store transitions to use to prevent catastrophic forgetting.\n","### ReplayMemory implements a ring buffer. Items are placed into memory\n","###    until memory reaches capacity, and then new items start replacing old items\n","###    at the beginning of the array.\n","### Member variables:\n","###    capacity: (int) number of transitions that can be stored\n","###    memory: (array) holds transitions (state, action, next_state, reward)\n","###    position: (int) index of current location in memory to place the next transition.\n","class ReplayMemory(object):\n","\n","  def __init__(self, capacity):\n","    self.capacity = capacity\n","    self.memory = []\n","    self.position = 0\n","\n","  ### Store a transition in memory.\n","  def push(self, state, action, next_state, reward):\n","    ### WRITE YOUR CODE BELOW HERE\n","    new_item = (state, action, next_state, reward)\n","\n","    if len(self.memory) < self.capacity:\n","      self.memory.append(new_item)\n","    else:\n","      self.memory[self.position] = new_item\n","      self.position = (self.position + 1) % self.capacity\n","\n","    ### WRITE YOUR CODE ABOVE HERE\n","\n","  ### Return a batch of transition objects from memory containing batch_size elements.\n","  def sample(self, batch_size):\n","    return random.sample(self.memory, batch_size)\n","\n","  ### This allows one to call len() on a ReplayMemory object. E.g. len(replay_memory)\n","  def __len__(self):\n","    return len(self.memory)\n"]},{"cell_type":"markdown","metadata":{"id":"Xskf9M0_RurS"},"source":["## initializeOptimizer"]},{"cell_type":"markdown","metadata":{"id":"U63_PKEyUw9s"},"source":["Instantiate and return an optimizer from the torch optim package. Popular options include `optim.RMSProp`, `optim.SGD`, and `optim.Adam`. See [pytorch optim docs](https://pytorch.org/docs/stable/optim.html) for information on how to instantiate optimizers. At a minimum, you must pass in the parameters of the DQN so the optimizer knows about the neural network."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"8C17xRYCRrKc","executionInfo":{"status":"ok","timestamp":1712958654496,"user_tz":240,"elapsed":82,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Choose and instantiate an optimizer. A default example is given, which you can change.\n","### Input:\n","### - parameters: the DQN parameters\n","### Output:\n","### - the optimizer object\n","def initializeOptimizer(parameters):\n","    ### WRITE YOUR CODE BELOW HERE\n","    optimizer = optim.Adam(parameters, lr=0.005)\n","    ### WRITE YOUR CODE ABOVE HERE\n","    return optimizer"]},{"cell_type":"markdown","metadata":{"id":"MVVcvZO8RzAC"},"source":["## select_action"]},{"cell_type":"markdown","metadata":{"id":"KhgN1vhjVekB"},"source":["**Implement this function.** This function implements epsilon-greedy. This is for the agent in the environment. It is given one screen and returns one action. Function parameters:\n","\n","* state: a 1 x 3 x screen_height x screen_width tensor.\n","* policy_net: the DQN network\n","* num_actions: the number of actions in the game\n","* epsilon: the epsilon value between 0 and 1. Generate a random number. Use the policy network if the random number is greater than epsilon.\n","* steps_done: the number of steps executed prior to this call.\n","* bootstrap_threshold: the first few steps the agent execute will not be used to train.\n","\n","When querying the policy net, pass the state into the policy net DQN, which will output a vector of q-values. Take the max of the q-values.\n","\n","Regardless of whether you pick random or query the DQN, the output action should be a $1 \\times 1$ tensor. When querying the DQN, make sure the max of the output is in the right shape. Also wrap the query to the DQN in `with torch.no_grad():` to make sure that the action is not attached to the network's computation chain.\n","\n","When picking a random action, you will need to create a new tensor from scratch: `torch.tensor([[some_number]], device=DEVICE, dtype=torch.long)`.\n","\n","(Hint: when making a new tensor, make sure it gets created in the GPU's memory: ```torch.tensor(some_array, device=DEVICE, dtype=torch.long)```. ```DEVICE``` is a global set to \"cuda\" if you have a GPU or \"cpu\" otherwise.)\n","\n","\n","You may also change the epsilon (i.e. implement epsilon decay) and return the new epsilon. Typically this will be a function of the total number of training steps. Don't count bootstraping steps."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Fje2XRRYgYUp","executionInfo":{"status":"ok","timestamp":1712958258610,"user_tz":240,"elapsed":89,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Select an action to perform.\n","### If a random number [0..1] is greater than epsilon, then query the policy_network,\n","### otherwise use a random action.\n","### Inputs:\n","### - state: a tensor of shape 3 x screen_height x screen_width\n","### - policy_net: a DQN object\n","### - num_actions: number of actions available\n","### - epsilon: float [0..1] indicating whether to choose random or use the network\n","### - steps_done: number of previously executed steps\n","### - bootstrap_threshold: number of steps that must be executed before training begins\n","### This function should return:\n","### - A tensor of shape 1 x 1 that contains the number of the action to execute\n","### - The new epsilon value to use next time\n","def select_action(state, policy_net, num_actions, epsilon, steps_done = 0, bootstrap_threshold = 0):\n","    action = None\n","    new_epsilon = epsilon\n","    ### WRITE YOUR CODE BELOW HERE\n","    if random.random() <= new_epsilon:\n","      return torch.tensor([[random.randint(0,num_actions-1)]], device=DEVICE, dtype=torch.long).to(DEVICE), new_epsilon\n","    else:\n","      op = policy_net(state)\n","      action = torch.argmax(op).reshape((1,1))\n","      return action, new_epsilon\n","    ### WRITE YOUR CODE ABOVE HERE\n","    return action, new_epsilon\n"]},{"cell_type":"markdown","metadata":{"id":"wI4RnXP2qEGu"},"source":["## Reward and Loss\n","\n","The reward function is as follows:\n","\n","* 100 points for touching a coin.\n","* 1 point for for every 1 unit of horizontal space to the right of the starting position (for reference, the easy level is about 8 units long).\n","\n","There is nothing you need to do here. The game tells the agent how many points it got after every action performed.\n","\n","Loss is accrued when the policy network is not able to compute q-values for two adjacent states that maintain the Bellman relationship:\n","\n","$$loss = R_{t+1} + \\gamma * max_{a'}Q(s_{t+1}, a') - Q(s_t, a_t)$$\n","\n","That is, the previous screen is different from the successor screen by being different by being a discounted version of the future best q-value (less reward).\n","\n","The next few functions build up each part of this loss equation."]},{"cell_type":"markdown","metadata":{"id":"lgKYPlpJR5yt"},"source":["## doMakeBatch"]},{"cell_type":"markdown","metadata":{"id":"R_0q7_i-XtwJ"},"source":["**Complete this function.** This function will get `batch_size` samples from the replay memory and create a batch. A batch allows us to run multiple screens through a GPU at once and get out multiple arrays of q-values one for each screen. Each row of the batch will be the pixels of a screen. Thus each row will be a $3 \\times h \\times w$ matrix of pixel values.\n","\n","When sampling from the replay memory, you will get back a number of Transition objects containing states, actions, next_states, and rewards. If the memory is of a terminal state then the next state will be `None`. For example:\n","\n","States | Actions | Next_states | Rewards\n","--- | --- | --- | ---\n","screen-1 (3 x h x w) | 2 | next_screen-1 (3 x h x w) | 2.6\n","screen-2 (3 x h x w) | 0 | None | 99.1\n","... | ... | ... | ...\n","screen-n (3 x h x w) | 1 | next_screen-n (3 x h x w) | 7.3\n","\n","Create tensors of the given size below, stacking up screens, actions, next-states, and rewards in the same order.\n","\n","If the transition was to a terminal state, then the next state in memory will be `None`. This presents a problem because we cannot have `None`s in the `next_states_batch` tensor. This also means that the `next_states_batch` could be smaller than the `states_batch` and this will make things mis-alighed. The `non_final_mask` will contain an array of booleans, where a 1 means the corresponding state did not transition to a terminal, and 0 means the corresponding state did transition to a terminal. The non_final_mask corresponding to the example above would be:\n","\n","Non_Final_Mask |\n","--- |\n","1 |\n","0 |\n","...\n","1 |\n","\n","Return the following:\n","\n","* *states_batch* is a tensor of size (batch_size x 3 x screen_height, screen_width) containing a batch of screens.\n","* *actions_batch* is a tensor of size (batch_size x 1) containing a batch of actions (integers). The order of actions should align with the order of states in *states_batch*.\n","* *rewards_batch* is a tensor of size (batch_size x 1) containing a batch of rewards (floats). The order of actions should align with the order of actions in *actions_batch*.\n","* *next_states_batch* is a tensor of size (batch_size x 3 x screen_height x screen_width) containing a batch of screens. If a state is terminal then next state is one that is after the simulation ends and thus ```None```.\n","* *non_final_mask* is a 1-D tensor of length batch_size containing 0 or 1 indicating whether a state in next_states_batch is non-terminal. 1 = non-terminal. 0 = terminal.\n","\n","(Note: in our codebase, the first dimension of a tensor is reserved for batching.)\n","\n","Now that we have a batch, broken up into a bunch of parts, we need to do a forward pass through the neural network to get the predicted Q-values for each state in the batch. With a GPU each state in the batch can be processed in parallel and produce a tensor containing the predicted utility of each action if it were to be executed in its corresponding state."]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Mjnp4s9RgbxZ","executionInfo":{"status":"ok","timestamp":1712958261671,"user_tz":240,"elapsed":101,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Ask for a batch of experience replays.\n","### Inputs:\n","### - replay_memory: A ReplayMemory object\n","### - batch_size: size of the batch to return\n","### Outputs:\n","### - states_batch: a tensor of shape batch_size x 3 x screen_height x screen_width\n","### - actions_batch: a tensor of shape batch_size x 1 containing action numbers\n","### - next_states_batch: a tensor containing screens.\n","### - rewards_batch: a tensor of shape batch_size x 1 containing reward values.\n","### - non_final_mask: a tensor of bools of length batch_size containing a 0 if the state is terminal or 1 otherwise\n","def doMakeBatch(replay_memory, batch_size):\n","    states_batch = []\n","    actions_batch = []\n","    next_states_batch = []\n","    rewards_batch = []\n","    non_final_mask = []\n","\n","    ### WRITE YOUR CODE BELOW HERE\n","    op = replay_memory.sample(batch_size)\n","    for (s,a,n,r) in op:\n","      states_batch.append(s)\n","      actions_batch.append(a)\n","\n","      if n!=None:\n","        next_states_batch.append(n)\n","      else:\n","        next_states_batch.append(s)\n","\n","      rewards_batch.append(r)\n","      non_final_mask.append(torch.tensor([0]) if n==None else torch.tensor([1]))\n","    ### WRITE YOUR CODE ABOVE HERE\n","\n","    return torch.cat(states_batch), torch.cat(actions_batch), torch.cat(next_states_batch), torch.cat(rewards_batch), torch.cat(non_final_mask)"]},{"cell_type":"markdown","metadata":{"id":"ZuhTG2aZR8wJ"},"source":["## doPredictQValues"]},{"cell_type":"markdown","metadata":{"id":"eK85nxvJap60"},"source":["**Complete the function.**\n","Given a batch of states, computed above, run the states through the policy network and [gather](https://pytorch.org/docs/stable/generated/torch.gather.html) the output q-values that correspond to each action in `actions_batch` (also computed above).\n","\n","That is, if the policy_network returns a batch of 3 sets of q-values:\n","```\n","[[0.1, 0.2, 0.3, 0.4],\n"," [0.5, 0.6, 0.7, 0.8],\n"," [0.9, 0.1, 0.2, 0.3]]\n","```\n","and the actions are:\n","```\n","[[1],\n"," [3],\n"," [0]]\n"," ```\n"," then you should return the q-values for these indexes. That is:\n"," ```\n"," [[0.2],\n","  [0.8],\n","  [0.9]]\n","```\n","These are the q-values for each of the three screens based on which action was taken when the agent encountered each of these screens."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ZLulwgrAgcjB","executionInfo":{"status":"ok","timestamp":1712958264508,"user_tz":240,"elapsed":211,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Ask the policy_net to predict the Q value for a batch of states and a batch of actions.\n","### Inputs:\n","### - policy_net: the DQN\n","### - states_batch: a tensor of shape batch_size x 3 x screen_height x screen_width containing screens\n","### - actions_batch: a tensor of shape batch_size x 1 containing action numbers\n","### Output:\n","### - A tensor of shape batch_size x 1 containing the Q-value predicted by the DQN in the position indicated by the action\n","def doPredictQValues(policy_net, states_batch, actions_batch):\n","    state_action_values = []\n","    ### WRITE YOUR CODE BELOW HERE\n","    ops = policy_net(states_batch)\n","    for i in range(len(actions_batch)):\n","      state_action_values.append(ops[i, actions_batch[i]])\n","    ### WRITE YOUR CODE ABOVE HERE\n","    ans = torch.cat(state_action_values).unsqueeze(1)\n","    return ans"]},{"cell_type":"markdown","metadata":{"id":"IVJ5HgVQSNgq"},"source":["## doPredictNextStateUtilities"]},{"cell_type":"markdown","metadata":{"id":"z97tRguHcJdq"},"source":["**Complete this function.** This function runs the `next_states_batch` through the policy network. `next_state_values` should be the max q-values coming from the policy network, so be sure to `.max()`. Also, `next_state_values` should be aligned with `states_batch`. Recall that `next_states_batch` may be smaller than the number of screens in `states_batch`. Use the `non_final_mask` to figure out which places in the tensor to place the q-values, and the rest should be zeros.\n","\n","Here is a fun trick:\n","```\n","x = torch.randint(0, 9, (3,)).long()\n","y = torch.zeros(6).long()\n","m = torch.tensor([1, 0, 1, 0, 1, 0]).bool()\n","y[m] = x\n","```\n","The `.detach()` at the end makes sure the outputs are not part of the computation graph."]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Em2AfgD1gecz","executionInfo":{"status":"ok","timestamp":1712958266985,"user_tz":240,"elapsed":116,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Ask the policy_net to predict the utility of a next_state.\n","### Inputs:\n","### - policy_net: The DQN\n","### - next_states_batch: a tensor of shape batch_size x 3 x screen_height x screen_width\n","### - non_final_mask: a tensor of length batch_size containing 0 for terminal states and 1 for non-terminal states\n","### - batch_size: the batch size\n","### Note: Only run non-terminal states through the policy_net\n","### Output:\n","### - A tensor of shape batch_size x 1 containing Q-values\n","def doPredictNextStateUtilities(policy_net, next_states_batch, non_final_mask, batch_size):\n","    next_state_values = torch.zeros(batch_size, device=DEVICE)\n","    ### WRITE YOUR CODE BELOW HERE\n","    for i in range(batch_size):\n","\n","      if non_final_mask[i] == 1:\n","        op = policy_net(next_states_batch[i].unsqueeze(0))\n","        next_state_values[i] = torch.max(op)\n","\n","    next_state_values = next_state_values.unsqueeze(1)\n","    ### WRITE YOUR CODE ABOVE HERE\n","    return next_state_values.detach()"]},{"cell_type":"markdown","metadata":{"id":"V9605CTaSQhR"},"source":["## doComputeExpectedQValues"]},{"cell_type":"markdown","metadata":{"id":"jXptPHYae5Jk"},"source":["**Complete the function.** Multiply the `next_state_values` by `gamma` and add to `rewards_batch`. We are building out part of the loss function."]},{"cell_type":"code","execution_count":28,"metadata":{"id":"ES5pukXuggdX","executionInfo":{"status":"ok","timestamp":1712958268710,"user_tz":240,"elapsed":111,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Compute the Q-update equation Q(s_t, a_t) = R(s_t+1) + gamma * argmax_a' Q(s_t+1, a')\n","### Inputs:\n","### - next_state_values: a tensor of shape batch_size x 1 containing Q values for state s_t+1\n","### - rewards_batch: a tensor or shape batch_size x 1 containing reward values for state s_t+1\n","### Output:\n","### - A tensor of shape batch_size x 1\n","def doComputeExpectedQValues(next_state_values, rewards_batch, gamma):\n","    expected_state_action_values = []\n","    ### WRITE YOUR CODE BELOW HERE\n","\n","    expected_state_action_values = rewards_batch + gamma * next_state_values\n","\n","    ### WRITE YOUR CODE ABOVE HERE\n","    return expected_state_action_values"]},{"cell_type":"markdown","metadata":{"id":"n3l9RwRlSS-b"},"source":["## doComputeLoss"]},{"cell_type":"markdown","metadata":{"id":"SGbEZImpfKbp"},"source":["**Complete the function.** The final step of computing loss is to compare the q-values of the current states to the discounted q-values of the next-states (plus any reward).\n","\n","`F.smooth_l1_loss()` will compute mean square difference of each row of two batches of values, and then return the average difference."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"KeePwmIDgja-","executionInfo":{"status":"ok","timestamp":1712958270255,"user_tz":240,"elapsed":146,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Compute the loss\n","### Inputs:\n","### - state_action_values: a tensor of shape batch_size x 1 containing Q values\n","### - expected_state_action_values: a tensor of shape batch_size x 1 containing updated Q values\n","### Output:\n","### - A tensor scalar value\n","def doComputeLoss(state_action_values, expected_state_action_values):\n","    loss = None\n","    ### WRITE YOUR CODE BELOW HERE\n","\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n","\n","    ### WRITE YOUR CODE ABOVE HERE\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"qHsR5t-qSVBk"},"source":["## doBackprop"]},{"cell_type":"markdown","metadata":{"id":"aU2bOujhgD3U"},"source":["**Complete the function**. Finally, backpropagate the loss through the policy network.\n","\n","ReLU activation functions can result in run-away gradients. It is generally a good idea to [clamp](https://pytorch.org/docs/stable/generated/torch.clamp.html) your gradients between -1 and 1. You can find the gradients in `p.grad.data` for each parameter `p` in `parameters`."]},{"cell_type":"code","execution_count":30,"metadata":{"id":"qKoDTe_ChEWd","executionInfo":{"status":"ok","timestamp":1712958271587,"user_tz":240,"elapsed":82,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}}},"outputs":[],"source":["### Run backpropagation. Make sure gradients are clipped between -1 and +1.\n","### Inputs:\n","### - loss: a tensor scalar\n","### - parameters: the parameters of the DQN\n","### There is no output\n","def doBackprop(loss, parameters):\n","    ### WRITE YOUR CODE BELOW HERE\n","    loss.backward()\n","    ### WRITE YOUR CODE ABOVE HERE"]},{"cell_type":"markdown","metadata":{"id":"KivfSnMYHdT7"},"source":["# Unit testing"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"CNWu5e1zoc8v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712958280763,"user_tz":240,"elapsed":7881,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"c1a4cb68-7b38-4453-b5e1-027a072fe2b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing ReplayMemory...\n","ReplayMemory test passed.\n","Testing doMakeBatch...\n","doMakeBatch test passed.\n","Testing doPredictQValues...\n","doPredictQValues test passed.\n","Testing doPredictNextStateUtilities...\n","doPredictNextStateUtilities test passed.\n","Testing doComputeExpectedQValues...\n","doComputeExpectedQValues test passed.\n","Testing doComputeLoss...\n","doComputeLoss test passed.\n"]}],"source":["### RUN UNIT TESTS ON FUNCTIONS\n","unit_test()\n"]},{"cell_type":"markdown","metadata":{"id":"L5twAqf6HhT8"},"source":["# Training and Evaluation"]},{"cell_type":"markdown","metadata":{"id":"FtRsLNl2hDBV"},"source":["Train your agent on each level. You can change the hyperparameters to be those that work the best.\n","\n","Each episode, you will receive some output, for example:\n","```\n","episode: 7 epsilon: 0.8566280064221765\n","duration: 1002\n","max reward: [2.6037602]\n","result: timeout\n","total steps: 16577\n","```\n","This tells us the episode number, and what epsilon is during that episode. It tells you how many steps the agent took during that episode (duration). The episode is terminated after about 1000 steps, so if the agent takes more than 1000 steps then it has failed to reach the coin. The max reward is the highest reward received during the episode. The agent receives 100 points for getting the coind, and one point per unit of travel along the x-dimension. In this example, the agent timed out and only went about 2.6 units of distance from the start.\n","\n","Set `SCREEN_SAVE = True` to generate images of the agent during evaluation. All the images are stored in the file system (to the left of the screen) under \"cache\". Go to the bottom of the notebook for functions for rendering and displaying videos. Note that the screen save option will slow down the evaluation training loop.\n","\n","The best model to date is saved in \"saved_models\".\n","\n","You will see the agent's duration fluctuate a lot from episode to episode. Early on this is because  is high and the agent is very random. The performance of the agent during training doesn't have a lot of predictive power about how the agent will perform during the next evaluation because  is set very low (0.1 or less).\n","\n","We do not set `epsilon=0` for testing. This allows for a small amount of randomness during testing. Without randomness, the agent's model would need to be very close to perfect or it will fail to reach the coin. For example, the agent may have learned to crouch or have failed to learn to jump up a ledge, in which case it agent will get stuck. A small amount of randomness means that the agent will occasionally make a move that may get it unstuck by transitioning the agent into a state in which it does know the right thing to do. If the agent relies too much on the randomness to make progress, we will see high durations. If the agent's policy is good the agent will make faster, and more steady progress resulting in lower durations even with some randomness.\n","\n","Here are some of the hyperparamters you might want to change:\n","\n","* ```BATCH_SIZE```: How many replay experiences to run through the neural network at once. Default is 128.\n","* ```NUM_EPISODES```: The max number of episodes to train. Default is 1000.\n","* ```REPLAY_CAPACITY```: How big is the replay buffer?\n","* ```BOOTSTRAP```: The number of steps the agent should run before training starts. This is to collect up replay experiences. Default is 10000.\n","* ```GAMMA```: The discount factor [0..1]. Default is 0.999, which means incorporate a lot of future utility into the current state's utility.\n","* ```EPSILON```: Probability of using a random action instead of the policy network [0..1]. The default is 0.9.\n","* ```EVAL_INTERVAL```: How many episodes to train before testing the network.\n","* ```TARGET_UPDATE```: One way of stabilizing DQN training is to compute the loss using an old version of the neural network. While counter intuitive that we should train against old information, each update of the neural network can radically change the utility calculations making it hard to find a pattern. This parameter indicates how slowly to update the target network (against which loss is computed). A value of 0 means that the agent should never use old network values. A value of 1+ indicates how many episodes of delay in updating the old network. The default is 0."]},{"cell_type":"markdown","metadata":{"id":"4wpw8at-hI_c"},"source":["**Easy level**"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"rVeaxxTLZEXp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712960320057,"user_tz":240,"elapsed":1292398,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"93e6cec6-1e93-480e-e9de-970ddd377dfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["screen size:  40 40\n","Making new model.\n","training...\n","episode: 0 epsilon: 0.9\n","duration: 788\n","max reward: [108.]\n","result: coin\n","total steps: 788 \n","\n","episode: 0 epsilon: 0.9\n","duration: 178\n","max reward: [107.187294]\n","result: coin\n","total steps: 966 \n","\n","episode: 0 epsilon: 0.9\n","duration: 794\n","max reward: [107.33622]\n","result: coin\n","total steps: 1760 \n","\n","episode: 0 epsilon: 0.9\n","duration: 202\n","max reward: [108.]\n","result: coin\n","total steps: 1962 \n","\n","episode: 0 epsilon: 0.9\n","duration: 185\n","max reward: [107.21176]\n","result: coin\n","total steps: 2147 \n","\n","episode: 0 epsilon: 0.9\n","duration: 1002\n","max reward: [5.796359]\n","result: timeout\n","total steps: 3149 \n","\n","episode: 0 epsilon: 0.9\n","duration: 1002\n","max reward: [5.6576385]\n","result: timeout\n","total steps: 4151 \n","\n","episode: 0 epsilon: 0.9\n","duration: 210\n","max reward: [107.877716]\n","result: coin\n","total steps: 4361 \n","\n","episode: 0 epsilon: 0.9\n","duration: 227\n","max reward: [107.5572]\n","result: coin\n","total steps: 4588 \n","\n","episode: 0 epsilon: 0.9\n","duration: 742\n","max reward: [108.]\n","result: coin\n","total steps: 5330 \n","\n","episode: 0 epsilon: 0.9\n","duration: 1002\n","max reward: [6.2696896]\n","result: timeout\n","total steps: 6332 \n","\n","episode: 0 epsilon: 0.9\n","duration: 164\n","max reward: [107.348816]\n","result: coin\n","total steps: 6496 \n","\n","episode: 0 epsilon: 0.9\n","duration: 467\n","max reward: [108.]\n","result: coin\n","total steps: 6963 \n","\n","episode: 0 epsilon: 0.9\n","duration: 834\n","max reward: [108.]\n","result: coin\n","total steps: 7797 \n","\n","episode: 0 epsilon: 0.9\n","duration: 247\n","max reward: [107.66359]\n","result: coin\n","total steps: 8044 \n","\n","episode: 0 epsilon: 0.9\n","duration: 556\n","max reward: [107.03605]\n","result: coin\n","total steps: 8600 \n","\n","episode: 0 epsilon: 0.9\n","duration: 923\n","max reward: [107.00768]\n","result: coin\n","total steps: 9523 \n","\n","episode: 0 epsilon: 0.9\n","duration: 269\n","max reward: [107.07897]\n","result: coin\n","total steps: 9792 \n","\n","episode: 0 epsilon: 0.9\n","duration: 930\n","max reward: [107.441925]\n","result: coin\n","total steps: 10722 \n","\n","episode: 1 epsilon: 0.9\n","duration: 319\n","max reward: [106.96541]\n","result: coin\n","total steps: 11041 \n","\n","episode: 2 epsilon: 0.9\n","duration: 150\n","max reward: [107.843056]\n","result: coin\n","total steps: 11191 \n","\n","episode: 3 epsilon: 0.9\n","duration: 69\n","max reward: [107.45154]\n","result: coin\n","total steps: 11260 \n","\n","episode: 4 epsilon: 0.9\n","duration: 1002\n","max reward: [3.566018]\n","result: timeout\n","total steps: 12262 \n","\n","episode: 5 epsilon: 0.9\n","duration: 1002\n","max reward: [5.2687573]\n","result: timeout\n","total steps: 13264 \n","\n","episode: 6 epsilon: 0.9\n","duration: 547\n","max reward: [107.026566]\n","result: coin\n","total steps: 13811 \n","\n","episode: 7 epsilon: 0.9\n","duration: 363\n","max reward: [107.00853]\n","result: coin\n","total steps: 14174 \n","\n","episode: 8 epsilon: 0.9\n","duration: 420\n","max reward: [106.93663]\n","result: coin\n","total steps: 14594 \n","\n","episode: 9 epsilon: 0.9\n","duration: 1002\n","max reward: [5.6987553]\n","result: timeout\n","total steps: 15596 \n","\n","episode: 10 epsilon: 0.9\n","duration: 454\n","max reward: [107.02645]\n","result: coin\n","total steps: 16050 \n","\n","Evaluating...\n","duration: 669\n","max reward: [107.97]\n","result: coin \n","\n","Evaluating...\n","duration: 360\n","max reward: [107.38676]\n","result: coin \n","\n","Evaluating...\n","duration: 963\n","max reward: [107.08396]\n","result: coin \n","\n","Evaluating...\n","duration: 678\n","max reward: [107.30046]\n","result: coin \n","\n","Evaluating...\n","duration: 796\n","max reward: [107.06836]\n","result: coin \n","\n","Average duration: 693.2\n","Average max reward: [107.3619]\n","Saving saved.model.10 ...\n","Done saving.\n"," \n","episode: 11 epsilon: 0.9\n","duration: 1002\n","max reward: [4.1680655]\n","result: timeout\n","total steps: 17052 \n","\n","episode: 12 epsilon: 0.9\n","duration: 873\n","max reward: [108.]\n","result: coin\n","total steps: 17925 \n","\n","episode: 13 epsilon: 0.9\n","duration: 1002\n","max reward: [2.562697]\n","result: timeout\n","total steps: 18927 \n","\n","episode: 14 epsilon: 0.9\n","duration: 92\n","max reward: [107.90175]\n","result: coin\n","total steps: 19019 \n","\n","episode: 15 epsilon: 0.9\n","duration: 208\n","max reward: [107.06046]\n","result: coin\n","total steps: 19227 \n","\n","episode: 16 epsilon: 0.9\n","duration: 1002\n","max reward: [5.8116713]\n","result: timeout\n","total steps: 20229 \n","\n","episode: 17 epsilon: 0.9\n","duration: 387\n","max reward: [108.]\n","result: coin\n","total steps: 20616 \n","\n","episode: 18 epsilon: 0.9\n","duration: 115\n","max reward: [107.466606]\n","result: coin\n","total steps: 20731 \n","\n","episode: 19 epsilon: 0.9\n","duration: 978\n","max reward: [108.]\n","result: coin\n","total steps: 21709 \n","\n","episode: 20 epsilon: 0.9\n","duration: 239\n","max reward: [107.97177]\n","result: coin\n","total steps: 21948 \n","\n","Evaluating...\n","duration: 743\n","max reward: [107.745804]\n","result: coin \n","\n","Evaluating...\n","duration: 95\n","max reward: [107.97]\n","result: coin \n","\n","Evaluating...\n","duration: 203\n","max reward: [107.905]\n","result: coin \n","\n","Evaluating...\n","duration: 506\n","max reward: [108.]\n","result: coin \n","\n","Evaluating...\n","duration: 322\n","max reward: [107.745804]\n","result: coin \n","\n","Average duration: 373.8\n","Average max reward: [107.873314]\n","Saving saved.model.20 ...\n","Done saving.\n"," \n","episode: 21 epsilon: 0.9\n","duration: 331\n","max reward: [107.83971]\n","result: coin\n","total steps: 22279 \n","\n","episode: 22 epsilon: 0.9\n","duration: 163\n","max reward: [107.61342]\n","result: coin\n","total steps: 22442 \n","\n","episode: 23 epsilon: 0.9\n","duration: 1002\n","max reward: [5.841894]\n","result: timeout\n","total steps: 23444 \n","\n","episode: 24 epsilon: 0.9\n","duration: 622\n","max reward: [107.51942]\n","result: coin\n","total steps: 24066 \n","\n","episode: 25 epsilon: 0.9\n","duration: 434\n","max reward: [107.36322]\n","result: coin\n","total steps: 24500 \n","\n","episode: 26 epsilon: 0.9\n","duration: 448\n","max reward: [106.96843]\n","result: coin\n","total steps: 24948 \n","\n","episode: 27 epsilon: 0.9\n","duration: 230\n","max reward: [107.8973]\n","result: coin\n","total steps: 25178 \n","\n","episode: 28 epsilon: 0.9\n","duration: 507\n","max reward: [107.984726]\n","result: coin\n","total steps: 25685 \n","\n","episode: 29 epsilon: 0.9\n","duration: 246\n","max reward: [107.78307]\n","result: coin\n","total steps: 25931 \n","\n","episode: 30 epsilon: 0.9\n","duration: 517\n","max reward: [107.910904]\n","result: coin\n","total steps: 26448 \n","\n","Evaluating...\n","duration: 91\n","max reward: [108.]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [6.024608]\n","result: timeout \n","\n","Evaluating...\n","duration: 331\n","max reward: [107.88707]\n","result: coin \n","\n","Evaluating...\n","duration: 492\n","max reward: [107.784935]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [6.0146337]\n","result: timeout \n","\n","Average duration: 583.6\n","Average max reward: [67.14226]\n"," \n","episode: 31 epsilon: 0.9\n","duration: 673\n","max reward: [107.380714]\n","result: coin\n","total steps: 27121 \n","\n","episode: 32 epsilon: 0.9\n","duration: 418\n","max reward: [107.827065]\n","result: coin\n","total steps: 27539 \n","\n","episode: 33 epsilon: 0.9\n","duration: 425\n","max reward: [107.10083]\n","result: coin\n","total steps: 27964 \n","\n","episode: 34 epsilon: 0.9\n","duration: 970\n","max reward: [107.35162]\n","result: coin\n","total steps: 28934 \n","\n","episode: 35 epsilon: 0.9\n","duration: 267\n","max reward: [107.01327]\n","result: coin\n","total steps: 29201 \n","\n","episode: 36 epsilon: 0.9\n","duration: 1002\n","max reward: [3.0325408]\n","result: timeout\n","total steps: 30203 \n","\n","episode: 37 epsilon: 0.9\n","duration: 1002\n","max reward: [6.0835757]\n","result: timeout\n","total steps: 31205 \n","\n","episode: 38 epsilon: 0.9\n","duration: 189\n","max reward: [106.970825]\n","result: coin\n","total steps: 31394 \n","\n","episode: 39 epsilon: 0.9\n","duration: 1002\n","max reward: [5.5182314]\n","result: timeout\n","total steps: 32396 \n","\n","episode: 40 epsilon: 0.9\n","duration: 581\n","max reward: [107.25726]\n","result: coin\n","total steps: 32977 \n","\n","Evaluating...\n","duration: 305\n","max reward: [106.95485]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [5.651305]\n","result: timeout \n","\n","Evaluating...\n","duration: 217\n","max reward: [107.93739]\n","result: coin \n","\n","Evaluating...\n","duration: 528\n","max reward: [107.97]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [5.8456383]\n","result: timeout \n","\n","Average duration: 610.8\n","Average max reward: [66.87184]\n"," \n","episode: 41 epsilon: 0.9\n","duration: 73\n","max reward: [107.190125]\n","result: coin\n","total steps: 33050 \n","\n","episode: 42 epsilon: 0.9\n","duration: 600\n","max reward: [107.04539]\n","result: coin\n","total steps: 33650 \n","\n","episode: 43 epsilon: 0.9\n","duration: 614\n","max reward: [108.]\n","result: coin\n","total steps: 34264 \n","\n","episode: 44 epsilon: 0.9\n","duration: 1002\n","max reward: [4.4421635]\n","result: timeout\n","total steps: 35266 \n","\n","episode: 45 epsilon: 0.9\n","duration: 1002\n","max reward: [5.0689716]\n","result: timeout\n","total steps: 36268 \n","\n","episode: 46 epsilon: 0.9\n","duration: 953\n","max reward: [107.387276]\n","result: coin\n","total steps: 37221 \n","\n","episode: 47 epsilon: 0.9\n","duration: 328\n","max reward: [107.83643]\n","result: coin\n","total steps: 37549 \n","\n","episode: 48 epsilon: 0.9\n","duration: 782\n","max reward: [107.24366]\n","result: coin\n","total steps: 38331 \n","\n","episode: 49 epsilon: 0.9\n","duration: 240\n","max reward: [107.07616]\n","result: coin\n","total steps: 38571 \n","\n","episode: 50 epsilon: 0.9\n","duration: 652\n","max reward: [107.97]\n","result: coin\n","total steps: 39223 \n","\n","Evaluating...\n","duration: 1002\n","max reward: [6.0469966]\n","result: timeout \n","\n","Evaluating...\n","duration: 295\n","max reward: [107.745804]\n","result: coin \n","\n","Evaluating...\n","duration: 766\n","max reward: [107.94177]\n","result: coin \n","\n","Evaluating...\n","duration: 469\n","max reward: [106.8877]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [2.447154]\n","result: timeout \n","\n","Average duration: 706.8\n","Average max reward: [66.21388]\n"," \n","episode: 51 epsilon: 0.9\n","duration: 851\n","max reward: [108.]\n","result: coin\n","total steps: 40074 \n","\n","episode: 52 epsilon: 0.9\n","duration: 290\n","max reward: [107.26599]\n","result: coin\n","total steps: 40364 \n","\n","episode: 53 epsilon: 0.9\n","duration: 163\n","max reward: [107.00056]\n","result: coin\n","total steps: 40527 \n","\n","episode: 54 epsilon: 0.9\n","duration: 299\n","max reward: [107.70886]\n","result: coin\n","total steps: 40826 \n","\n","episode: 55 epsilon: 0.9\n","duration: 631\n","max reward: [107.938736]\n","result: coin\n","total steps: 41457 \n","\n","episode: 56 epsilon: 0.9\n","duration: 195\n","max reward: [107.03498]\n","result: coin\n","total steps: 41652 \n","\n","episode: 57 epsilon: 0.9\n","duration: 978\n","max reward: [107.16867]\n","result: coin\n","total steps: 42630 \n","\n","episode: 58 epsilon: 0.9\n","duration: 218\n","max reward: [107.06525]\n","result: coin\n","total steps: 42848 \n","\n","episode: 59 epsilon: 0.9\n","duration: 477\n","max reward: [108.]\n","result: coin\n","total steps: 43325 \n","\n","episode: 60 epsilon: 0.9\n","duration: 897\n","max reward: [107.69926]\n","result: coin\n","total steps: 44222 \n","\n","Evaluating...\n","duration: 755\n","max reward: [107.57236]\n","result: coin \n","\n","Evaluating...\n","duration: 941\n","max reward: [108.]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [5.641214]\n","result: timeout \n","\n","Evaluating...\n","duration: 905\n","max reward: [107.97]\n","result: coin \n","\n","Evaluating...\n","duration: 910\n","max reward: [107.88707]\n","result: coin \n","\n","Average duration: 902.6\n","Average max reward: [87.41414]\n"," \n","episode: 61 epsilon: 0.9\n","duration: 200\n","max reward: [107.82143]\n","result: coin\n","total steps: 44422 \n","\n","episode: 62 epsilon: 0.9\n","duration: 152\n","max reward: [107.075485]\n","result: coin\n","total steps: 44574 \n","\n","episode: 63 epsilon: 0.9\n","duration: 360\n","max reward: [107.25065]\n","result: coin\n","total steps: 44934 \n","\n","episode: 64 epsilon: 0.9\n","duration: 1002\n","max reward: [6.7365127]\n","result: timeout\n","total steps: 45936 \n","\n","episode: 65 epsilon: 0.9\n","duration: 1002\n","max reward: [6.3892612]\n","result: timeout\n","total steps: 46938 \n","\n","episode: 66 epsilon: 0.9\n","duration: 133\n","max reward: [107.910904]\n","result: coin\n","total steps: 47071 \n","\n","episode: 67 epsilon: 0.9\n","duration: 883\n","max reward: [106.99972]\n","result: coin\n","total steps: 47954 \n","\n","episode: 68 epsilon: 0.9\n","duration: 1002\n","max reward: [6.7540107]\n","result: timeout\n","total steps: 48956 \n","\n","episode: 69 epsilon: 0.9\n","duration: 581\n","max reward: [108.]\n","result: coin\n","total steps: 49537 \n","\n","episode: 70 epsilon: 0.9\n","duration: 702\n","max reward: [107.00276]\n","result: coin\n","total steps: 50239 \n","\n","Evaluating...\n","duration: 1002\n","max reward: [5.2666655]\n","result: timeout \n","\n","Evaluating...\n","duration: 590\n","max reward: [108.]\n","result: coin \n","\n","Evaluating...\n","duration: 899\n","max reward: [106.99215]\n","result: coin \n","\n","Evaluating...\n","duration: 442\n","max reward: [108.]\n","result: coin \n","\n","Evaluating...\n","duration: 352\n","max reward: [107.47852]\n","result: coin \n","\n","Average duration: 657.0\n","Average max reward: [87.14747]\n"," \n","episode: 71 epsilon: 0.9\n","duration: 289\n","max reward: [107.23171]\n","result: coin\n","total steps: 50528 \n","\n","episode: 72 epsilon: 0.9\n","duration: 220\n","max reward: [107.01783]\n","result: coin\n","total steps: 50748 \n","\n","episode: 73 epsilon: 0.9\n","duration: 101\n","max reward: [108.]\n","result: coin\n","total steps: 50849 \n","\n","episode: 74 epsilon: 0.9\n","duration: 1002\n","max reward: [6.2953153]\n","result: timeout\n","total steps: 51851 \n","\n","episode: 75 epsilon: 0.9\n","duration: 620\n","max reward: [108.]\n","result: coin\n","total steps: 52471 \n","\n","episode: 76 epsilon: 0.9\n","duration: 513\n","max reward: [107.05012]\n","result: coin\n","total steps: 52984 \n","\n","episode: 77 epsilon: 0.9\n","duration: 458\n","max reward: [108.]\n","result: coin\n","total steps: 53442 \n","\n","episode: 78 epsilon: 0.9\n","duration: 610\n","max reward: [106.99893]\n","result: coin\n","total steps: 54052 \n","\n","episode: 79 epsilon: 0.9\n","duration: 332\n","max reward: [107.03124]\n","result: coin\n","total steps: 54384 \n","\n","episode: 80 epsilon: 0.9\n","duration: 454\n","max reward: [107.04454]\n","result: coin\n","total steps: 54838 \n","\n","Evaluating...\n","duration: 437\n","max reward: [106.97755]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [5.5511026]\n","result: timeout \n","\n","Evaluating...\n","duration: 544\n","max reward: [107.008514]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [2.4623866]\n","result: timeout \n","\n","Evaluating...\n","duration: 695\n","max reward: [107.97]\n","result: coin \n","\n","Average duration: 736.0\n","Average max reward: [65.99391]\n"," \n","episode: 81 epsilon: 0.9\n","duration: 231\n","max reward: [107.003944]\n","result: coin\n","total steps: 55069 \n","\n","episode: 82 epsilon: 0.9\n","duration: 1002\n","max reward: [6.00201]\n","result: timeout\n","total steps: 56071 \n","\n","episode: 83 epsilon: 0.9\n","duration: 1002\n","max reward: [6.2163677]\n","result: timeout\n","total steps: 57073 \n","\n","episode: 84 epsilon: 0.9\n","duration: 404\n","max reward: [107.39991]\n","result: coin\n","total steps: 57477 \n","\n","episode: 85 epsilon: 0.9\n","duration: 498\n","max reward: [107.709564]\n","result: coin\n","total steps: 57975 \n","\n","episode: 86 epsilon: 0.9\n","duration: 197\n","max reward: [107.773125]\n","result: coin\n","total steps: 58172 \n","\n","episode: 87 epsilon: 0.9\n","duration: 983\n","max reward: [107.77298]\n","result: coin\n","total steps: 59155 \n","\n","episode: 88 epsilon: 0.9\n","duration: 1002\n","max reward: [6.0704727]\n","result: timeout\n","total steps: 60157 \n","\n","episode: 89 epsilon: 0.9\n","duration: 411\n","max reward: [107.5235]\n","result: coin\n","total steps: 60568 \n","\n","episode: 90 epsilon: 0.9\n","duration: 1002\n","max reward: [5.366951]\n","result: timeout\n","total steps: 61570 \n","\n","Evaluating...\n","duration: 142\n","max reward: [107.07235]\n","result: coin \n","\n","Evaluating...\n","duration: 117\n","max reward: [107.717735]\n","result: coin \n","\n","Evaluating...\n","duration: 1002\n","max reward: [2.3287842]\n","result: timeout \n","\n","Evaluating...\n","duration: 569\n","max reward: [107.97]\n","result: coin \n","\n","Evaluating...\n","duration: 308\n","max reward: [107.827065]\n","result: coin \n","\n","Average duration: 427.6\n","Average max reward: [86.58318]\n"," \n","episode: 91 epsilon: 0.9\n","duration: 306\n","max reward: [107.87103]\n","result: coin\n","total steps: 61876 \n","\n","episode: 92 epsilon: 0.9\n","duration: 374\n","max reward: [107.58864]\n","result: coin\n","total steps: 62250 \n","\n","episode: 93 epsilon: 0.9\n","duration: 229\n","max reward: [107.265015]\n","result: coin\n","total steps: 62479 \n","\n","episode: 94 epsilon: 0.9\n","duration: 293\n","max reward: [106.98604]\n","result: coin\n","total steps: 62772 \n","\n","episode: 95 epsilon: 0.9\n","duration: 615\n","max reward: [107.54009]\n","result: coin\n","total steps: 63387 \n","\n","episode: 96 epsilon: 0.9\n","duration: 368\n","max reward: [107.70473]\n","result: coin\n","total steps: 63755 \n","\n","episode: 97 epsilon: 0.9\n","duration: 628\n","max reward: [107.53012]\n","result: coin\n","total steps: 64383 \n","\n","episode: 98 epsilon: 0.9\n","duration: 1002\n","max reward: [5.300743]\n","result: timeout\n","total steps: 65385 \n","\n","episode: 99 epsilon: 0.9\n","duration: 109\n","max reward: [107.62079]\n","result: coin\n","total steps: 65494 \n","\n","Training complete\n"]}],"source":["SAVE_FILENAME = 'saved.model'\n","LOAD_FILENAME = None\n","TRAIN_SEED = EASY_LEVEL\n","policy_net = train(num_episodes=100,\n","                   load_filename=LOAD_FILENAME,\n","                   save_filename=SAVE_FILENAME,\n","                   eval_interval=EVAL_INTERVAL,\n","                   replay_capacity=100,\n","                   bootstrap_threshold=10000,\n","                   target_update=TARGET_UPDATE,\n","                   epsilon=EPSILON,\n","                   eval_epsilon=EVAL_EPSILON,\n","                   gamma=GAMMA,\n","                   batch_size=BATCH_SIZE,\n","                   random_seed=RANDOM_SEED,\n","                   seed=TRAIN_SEED)"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"8-LNqy8SVoJx","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1712960404167,"user_tz":240,"elapsed":161,"user":{"displayName":"Aishwarya Solanki","userId":"09592093339780675910"}},"outputId":"c089797d-7fa7-45f8-ad5f-65d1d98a9924"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'EASY_LEVEL' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-de5bb9166407>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mTEST_FILENAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'saved.model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTEST_SEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEASY_LEVEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meval_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEVAL_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEVAL_EPSILON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEST_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'EASY_LEVEL' is not defined"]}],"source":["TEST_FILENAME = 'saved.model'\n","TEST_SEED = EASY_LEVEL\n","eval_net = load_model(TEST_FILENAME)\n","for _ in range(EVAL_COUNT):\n","  evaluate(eval_net, epsilon=EVAL_EPSILON, test_seed=TEST_SEED)\n"]},{"cell_type":"markdown","metadata":{"id":"6n4M6dTQnMjB"},"source":["**Medium Level**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Am2kUiHdnOzo"},"outputs":[],"source":["SAVE_FILENAME = 'saved.model'\n","LOAD_FILENAME = None\n","TRAIN_SEED = MEDIUM_LEVEL\n","policy_net = train(num_episodes=NUM_EPISODES,\n","                   load_filename=LOAD_FILENAME,\n","                   save_filename=SAVE_FILENAME,\n","                   eval_interval=EVAL_INTERVAL,\n","                   replay_capacity=REPLAY_CAPACITY,\n","                   bootstrap_threshold=BOOTSTRAP,\n","                   target_update=TARGET_UPDATE,\n","                   epsilon=EPSILON,\n","                   eval_epsilon=EVAL_EPSILON,\n","                   gamma=GAMMA,\n","                   batch_size=BATCH_SIZE,\n","                   random_seed=RANDOM_SEED,\n","                   seed=TRAIN_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bCKOeaVhnSYr"},"outputs":[],"source":["TEST_FILENAME = 'saved.model'\n","TEST_SEED = MEDIUM_LEVEL\n","eval_net = load_model(TEST_FILENAME)\n","for _ in range(EVAL_COUNT):\n","  evaluate(eval_net, epsilon=EVAL_EPSILON, test_seed=TEST_SEED)"]},{"cell_type":"markdown","metadata":{"id":"GjD40kmnnVyS"},"source":["**One Monster Level**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwPrKPmGnY2k"},"outputs":[],"source":["SAVE_FILENAME = 'saved.model'\n","LOAD_FILENAME = None\n","TRAIN_SEED = ONE_MONSTER\n","policy_net = train(num_episodes=NUM_EPISODES,\n","                   load_filename=LOAD_FILENAME,\n","                   save_filename=SAVE_FILENAME,\n","                   eval_interval=EVAL_INTERVAL,\n","                   replay_capacity=REPLAY_CAPACITY,\n","                   bootstrap_threshold=BOOTSTRAP,\n","                   target_update=TARGET_UPDATE,\n","                   epsilon=EPSILON,\n","                   eval_epsilon=EVAL_EPSILON,\n","                   gamma=GAMMA,\n","                   batch_size=BATCH_SIZE,\n","                   random_seed=RANDOM_SEED,\n","                   seed=TRAIN_SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrKuZzlwncDG"},"outputs":[],"source":["TEST_FILENAME = 'saved.model'\n","TEST_SEED = ONE_MONSTER\n","eval_net = load_model(TEST_FILENAME)\n","for _ in range(EVAL_COUNT):\n","  evaluate(eval_net, epsilon=EVAL_EPSILON, test_seed=TEST_SEED)"]},{"cell_type":"markdown","metadata":{"id":"TskacoAEugsC"},"source":["## Tips on debugging\n","\n","**pdb**\n","\n","pdb is a python debuggin tool that runs from the command line or Colab notebooks. Use ```pdb.set_trace()``` to create a break-point with a prompt. Print variables and inspect their values to get a sense of what is going on.\n","\n","**Tensors and their shapes**\n","\n","Tensors can be thought of as multi-dimensional arrays of input or output data for the neural network. They operate very much like regular python arrays and support indexing.\n","\n","Be mindful that your data is in tensors of the correct shapes. A good thing to do is use *pdb* to interrupt execution and check whether your tensor shapes are correct. Use ```tensor.size()``` to inspect a tensor's shape.\n","\n","Sometimes you will need to create new tensors from scratch. Here is a quick cheatsheet:\n","\n","* ```torch.zeros(dim_1, dim_2, ..., dim_n)``` --- This creates an *n*-dimensional tensor filled with zeros.\n","* ```torch.ones(dim_1, dim_2, ..., dim_n)``` --- This creates an *n*-dimensional tensor filled with ones.\n","* ```torch.tensor(array)``` --- This creates a tensor of the same dimensions as a regular python array. For example ```array = [1, 2, 3]``` will create a 1-D tensor, ```array = [[11, 12, 13], [21, 22, 23], [31, 32, 33]]``` will create a 2-D tensor of shape 3 x 3, etc.\n","\n","It is generally a good idea to indicate whether a tensor lives on the CPU or the GPU. The ```DEVICE``` global is set to ```\"cuda\"``` if a GPU is available or set to ```\"cpu\"``` otherwise. When you create a tensor you can indicate where it lives: ```torch.zeros(10, device=\"cuda\")``` or ```torch.zeros(10, device=\"cpu\")``` or ```torch.zeros(10, device=DEVICE)```. You can move tensors from CPU to GPU or vice versa by using ```tensor.to()```.\n","\n","When creating a tensor you might also want to specify the type of data that is being stored. For example:\n","* ```torch.zeros(10, dtype=torch.uint8)``` creates a tensor of bytes.\n","* ```torch.zeros(10, dtype=torch.long)``` creates a tensor of longs.\n","* ```torch.zeros(10, dtype=torch.float)``` creates a tensor of floats.\n","\n","**Tensor slicing and stacking**\n","\n","Generally speaking, you should not have to write any loops. Loops are slow. Tensors can be manipulated in place in parallel.\n","\n","* Slicing: `2d_tensor[0, :]` will get the first column of a 2d tensor\n","* Evaluating: `tensor_x > 0` will create a new tensor of booleans with true whereever there is a positive number.\n","* Stacking: `torch.stack([t1, t2, t3])` will create a new tensor that is made of t1, t2, and t3 stacked on top of each other.\n","* Concatenating: `torch.cat(t1, t2, dim=0)` concatenate t1 and t2 along the zeroth-dimension.\n","* Squeezing and unsqueezing: `t1.unsqueeze(dim=0)` will add an extra zeroth dimension to the tensor. For example `[[1, 2], [3, 4]]` will become `[[[1, 2], [3, 4]]]]`\n","* Adding, multiplying, dividing:\n","`t1 + t2`,\n","`t1 * t2`,\n","`t3 / n`.\n","* Maxing, means, etc: `t1.max(dim=1)` will get the max value along dimension 1 (a row). `t1.mean()` will compute the mean value. If there is a mathematical function you want to use, it is probably already built in to torch."]},{"cell_type":"markdown","metadata":{"id":"NwsTL1mJHpPu"},"source":["# Download The Model"]},{"cell_type":"markdown","metadata":{"id":"sSKonDBImXPh"},"source":["This will take a model and make sure it is in \"cpu\" mode so it can run on a computer without a GPU. You can then download it from files."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vwWE-O3MYNVy"},"outputs":[],"source":["### USE THIS TO COVERT A MODEL FROM CUDA TO CPU\n","### DOWNLOAD USING THE FILES MENU TO THE LEFT\n","net = load_model('saved.model')\n","net = net.to('cpu')\n","torch.save(net, os.path.join(MODEL_PATH, 'saved_cpu.model.first'))"]},{"cell_type":"markdown","metadata":{"id":"wvvlCorlujuV"},"source":["# Show Evaluation Movies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xI86Kjpq-MST"},"outputs":[],"source":["# This seems to work but is really slow and flickery\n","\n","import matplotlib.pyplot as plt\n","from IPython import display as ipythondisplay\n","\n","def show_movie(num):\n","  dir_name = str(num)\n","  files = []\n","  for file in os.listdir(os.path.join(TEMP_DIR, dir_name)):\n","    files.append(file)\n","  sorted_files = sorted(files, key=lambda f:int(f[len(SCREEN_SAVE_PREFIX):-len(SCREEN_SAVE_POSTFIX)]))\n","  for file in sorted_files:\n","    img = Image.open(os.path.join(TEMP_DIR, dir_name, file), 'r')\n","    plt.imshow(img)\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(plt.gcf())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0ghxICB_jOf"},"outputs":[],"source":["Eval_run_number = 1\n","show_movie(Eval_run_number)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZnUNSzDu3a_"},"outputs":[],"source":["# Alternatively, we can make an animated gif.\n","# This runs faster and doesn't flicker once loaded.\n","# Unfortunately, colab loads animated gifs really slow.\n","# Better to download and view on own machine, but this is cumbersome.\n","\n","import PIL\n","from PIL import Image\n","import shutil\n","\n","def make_anim(num):\n","  dir_name = str(num)\n","  files = []\n","  images = []\n","  for file in os.listdir(os.path.join(TEMP_DIR, dir_name)):\n","    files.append(file)\n","  sorted_files = sorted(files, key=lambda f:int(f[len(SCREEN_SAVE_PREFIX):-len(SCREEN_SAVE_POSTFIX)]))\n","  for file in sorted_files:\n","    try:\n","      img = Image.open(os.path.join(TEMP_DIR, dir_name, file))\n","      images.append(img)\n","    except:\n","      print(os.path.join(TEMP_DIR, dir_name, file), \"did not load.\")\n","  images[0].save('movie' + str(num) + '.gif', \"GIF\",\n","                      save_all=True,\n","                      append_images=images[1:],\n","                      duration=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipjqzvkJlh2w"},"outputs":[],"source":["Eval_run_number = 1\n","make_anim(Eval_run_number)"]},{"cell_type":"markdown","metadata":{"id":"cqnZ71UvmLht"},"source":["# Grading\n","\n","Submit your colab notebook to Gradescope with cell outputs saved. Submit three model files, one for `EASY_LEVEL`, one for `MEDIUM_LEVEL`, and one for `ONE_MOSTER`. Name your files \"easy_model\", \"medium_model\", and \"monster_model\", respectively.\n","\n","* 2 point: Pass unit tests\n","* 1 point: Training loop executes 10 episodes and produces a valid model with gradients.\n","* 3 points: Train a network that can beat ```EASY_LEVEL``` in less than 150 duration (averaged over 10 runs, with evaluation epsilon 0.1)\n","* 1 point: Train a network that can beat ```EASY_LEVEL``` in less than 100 duration (averaged over 10 runs, with evaluation epsilon 0.1)\n","* 1 point: Train a network that can beat ```EASY_LEVEL``` in less than 50 duration (averaged over 10 runs, with evaluation epsilon 0.1)\n","* 1 point: Train a network that can beat ```MEDIUM_LEVEL``` in less than 150 duration (averaged over 10 runs, with evaluation epsilon 0.1)\n","* 1 point: Train a network that can beat the ```ONE_MONSTER``` level in less than 300 duration (averaged over 10 runs, with evaluation epsilon 0.1)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1-nIyi36JzcF3djS8kuHeb9sVreg2x9_s","timestamp":1711590302189},{"file_id":"1tgNm4oJ0dMJOb-vxpa4Y9zpL0M2Nrq5y","timestamp":1711582518776},{"file_id":"1LrPn9WaykReH_gWdlgxTbfMMAXsNZhRV","timestamp":1586128706555},{"file_id":"11cO5w2NM2Rhs_ET8Gooz86IT8l0LardH","timestamp":1585103635025}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}