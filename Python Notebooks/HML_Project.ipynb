{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP563ugrOAmbo3TmJ9BrgiK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Init"],"metadata":{"id":"jbiav-aZPLZH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHZQtrRfOi-r"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from transformers import ViTForImageClassification, ViTFeatureExtractor\n","import os\n"]},{"cell_type":"markdown","source":["# Define device"],"metadata":{"id":"LTMbCsTAPKYy"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"Q41XLfalOncU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameters"],"metadata":{"id":"i7WCqbU8PJI1"}},{"cell_type":"code","source":["batch_size = 32\n","learning_rate = 1e-4\n","num_epochs = 5\n","checkpoint_dir = './checkpoints'"],"metadata":{"id":"fbJ5rJ34Opm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create checkpoint directory if it doesn't exist"],"metadata":{"id":"X6L5AGVIPFVo"}},{"cell_type":"code","source":["os.makedirs(checkpoint_dir, exist_ok=True)"],"metadata":{"id":"gBA7cQfSOrPz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load dataset"],"metadata":{"id":"RVg4mfZ2PEOQ"}},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"ERydobFLOt_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Vision Transformer (ViT)"],"metadata":{"id":"_iAhCJZKPB6T"}},{"cell_type":"code","source":["model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=10)\n","model.to(device)"],"metadata":{"id":"9Z2ORW3yOviR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define loss function and optimizer"],"metadata":{"id":"44gYJVHNO_9W"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"sJeljp5wOzH8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Function to evaluate model"],"metadata":{"id":"trwhpUgOO-HE"}},{"cell_type":"code","source":["def evaluate(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in dataloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images).logits\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","    return correct / total\n"],"metadata":{"id":"oYwRpGi8O0S-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training loop with checkpointing"],"metadata":{"id":"02N7WISsO6ZH"}},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        # Forward pass\n","        outputs = model(images).logits\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    # Save checkpoint\n","    checkpoint_path = os.path.join(checkpoint_dir, f'vit_epoch_{epoch + 1}.pth')\n","    torch.save({'epoch': epoch + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': running_loss}, checkpoint_path)\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss:.4f}, Checkpoint saved at {checkpoint_path}\")\n","\n","    # Evaluate the model\n","    accuracy = evaluate(model, test_loader)\n","    print(f\"Validation Accuracy after Epoch {epoch + 1}: {accuracy * 100:.2f}%\")\n","\n","print(\"Training complete!\")"],"metadata":{"id":"iR_dZJerO2Lh"},"execution_count":null,"outputs":[]}]}