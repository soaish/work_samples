# Answers
1. Yes, i computed the model fit to distance effect and to the ratio effect. The correlation values mean how closely related a data point is to another data point. For example, the values for same number was always 1, 100%, because their cosine similarity is the same and calculating distance between those vector is a value 0 which means they are the same value. Like the case for 1 and 1 or 7 and 7, the correlation of these values is 1. However, we do see some other values like 5 and 7 that also have the cosine similarity that is something that is up for discussion. In the linear fit plot, we can see the linear fit line vs the data points we just plotted and we can see they are following a similar trajectory but linear fit curve is obviously a straight line and the data points I came up with have a slight parabolic structure. For the distance and ratio effects, a higher r (correlation) value would indicate that the model's predictions align well with the observed data, suggesting psychological plausibility.
For the r^2 values, it is almost contrary to the previous discussion, it states that the more similar the two numbers being compared are, the more time it takes to compare them. The R^2 value was very close to 1 as anticipated - R-squared value = 0.9900917970135978. In the curve plotted above, we plotted the cosine similarity of a ratio max(n1, n2) / min(n1, n2) to avg similarities rather than just distance between them to avg similarities. We can see that the linear fit line is much closely emulating the ratio vs avg similarity line. A high R^2 suggests that the model is capturing a significant part of the effects' variability, meaning the model closely mimics how humans perceive distance and size differences. It is an extremely interesting concept.
2. Yes, i think the check-pointed CNN models would mimic the development progression shown by children. A toddler can be compared to a newly trained CNN model which might make mistakes and might give delayed answers, so we could see that blue line with a lot of deviations. An adult can be compared to a heavily trained high accuracy CNN model which might give all the answers within less than 0.5s and most of them accurate. It is a very interesting hypothesis but to think about how humans are mature at 25, CNN models can mature within a few days. So in spite of showing the same graphs and same trends, the lifespan might be much shorter for a model as compared to humans.
3. The answers at the final fully connected layers are what we see as results but if we have to talk about what do we see in the intermediate layers we would have to understand how and what the layers are and do. At a high level, I'd think the process in the intermediate layer focuses on various characteristics like edge detection, or lines, textures, and as it comes to the final layer the number is processed correctly. For example, if we talk about the number 7, the intermediate layers might have partially incorrectly narrowed it down to either 1 or 7, and as we approach the final layer, the model reaches a conclusion that due to a number of factors taken into account, this is in fact 7 and not 1. Or another example could be number 8, which looks like 2 number "3"'s stacked against each other. Some of the intermediate layers might only process the right half of the image and consider it as 3 but later as it goes on, it might consider the top loop and consider it the number 9 instead of 8, towards the final layer is where we really drill down and conclude that it is actually an 8 all along. In conclusion, the same patterns seen at the final layer may not be as clear earlier because earlier layers prioritize lower-level image characteristics, not abstract numerical processing.
4. It is because of visual representation of numbers, like the number 1 has typical characteristics that number 5 clearly doesn't, talking about totally different looking numbers. Numbers 1 and 7 have different characteristics but can often be misinterpreted because of certain similar characteristics like the straight line and one line extending from the top left. And i think that most classifications have to deal with numbers every now and then like there are 5 different sets of images and for the vision model to correctly classify these images into 5 different clusters, this involves some sort of quantitative distinctions and that leads to my point that there is some overlap between the normal classification a model does with it classifying numerical information with a greater sensitivity. Plus the work on images have begun recently, the work on number parsing and OCR technologies has been in works since decades that might also contribute to the advancement in numerical sensitivity. The dataset on the other hand might have played a role too, comparing the number "1" to lets say a "beak" of a bird, the number 1 hasn't changed since the advent of time for the sake of simplicity vs due to evolution, the beak has evolved too and we have discovered more species of birds so we have more variety of birds and beaks, and the dataset is not the same as it used to.
5. The exercise shows that there is a close relation between how humans classify numbers and how a vision model does too. It is indeed a big leap for cognitive science, computer vision research, and artificial intelligence because in a way we are getting closer to understanding how a human brain works and how to emulate it. If a vision model is able to correctly classify numbers, it will also means that we will need less numbers of other models that specialize in this task, for example, instead of having OCR technology and a separate complicated neural network correctly identifying only numbers, we can just have one vision model to train and correctly classify numbers. In the bigger scheme of things, it will help reduce the Carbon footprints machine learning or Artificial Intelligence models have due to the extensive power usage during the training phase.