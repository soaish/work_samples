{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c05628-c946-421d-8dff-95c5410d5e14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sample ARC Submission\n",
    "\n",
    "This is a sample notebook that can help get you started with creating an ARC Prize submission. It covers the basics of loading libraries, loading data, implementing an approach, and submitting.\n",
    "\n",
    "You should be able to submit this notebook to the evaluation portal and have it run successfully (although you'll get a score of 0, so you'll need to do some work if you want to do better!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717270ed-182b-4598-8f12-612cd62de60e",
   "metadata": {},
   "source": [
    "# Load needed libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dd6cc-7da7-4bec-a211-ff9afb2e688a",
   "metadata": {},
   "source": [
    "Basic libraries like numpy, torch, matplotlib, and tqdm are already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3d361d-d3e0-45d2-b416-803c0ad1822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae22af4-5a95-40d1-ac1f-f611b77578c7",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4bf5a-3237-46f6-ab05-2319a0497a8b",
   "metadata": {},
   "source": [
    "Here we are loading the training challenges and solutions (this is the public training set), the evaluation challenges and solutions (this is the public evaluation set), and the test challenges (currently a placeholder file that is a copy of the public evaluation challanges).\n",
    "\n",
    "For your initial testing and exploration, I'd recommend not using the public evaluation set, just work off the public training set and then test against the test challenges (which is actually the public evaluation set). However, when competing in the competition, then you can should probably use the evaluation tasks for training too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207605ea-58a7-46e0-9fd2-3ee2000eece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public training set\n",
    "train_challenges_path = '../input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "train_solutions_path = '../input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "\n",
    "with open(train_challenges_path) as fp:\n",
    "    train_challenges = json.load(fp)\n",
    "with open(train_solutions_path) as fp:\n",
    "    train_solutions = json.load(fp)\n",
    "\n",
    "# Public evaluation set\n",
    "evaluation_challenges_path = '../input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "evaluation_solutions_path = '../input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "\n",
    "with open(evaluation_challenges_path) as fp:\n",
    "    evaluation_challenges = json.load(fp)\n",
    "with open(evaluation_solutions_path) as fp:\n",
    "    evaluation_solutions = json.load(fp)\n",
    "\n",
    "# This will be the hidden test challenges (currently has a placeholder to the evaluation set)\n",
    "test_challenges_path = '../input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "with open(test_challenges_path) as fp:\n",
    "    test_challenges = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292806c-8c0c-4efd-9c30-b3660254e4c2",
   "metadata": {},
   "source": [
    "Here is an example of what a test task looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be570a8b-7105-4935-b538-5e58794406f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n"
     ]
    }
   ],
   "source": [
    "sample_task = list(test_challenges.keys())[0]\n",
    "print(test_challenges[sample_task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f34083-882b-4fb9-b5fd-92dd75772dc3",
   "metadata": {},
   "source": [
    "# Generating a submission\n",
    "\n",
    "To generate a submission you need to output a file called `submission.json` that has the following format:\n",
    "\n",
    "```\n",
    "{\"00576224\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
    " \"009d5c81\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
    " \"12997ef3\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]},\n",
    "              {\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "In this case, the task ids come from `test_challenges`. There may be multiple (i.e., >1) test items per task. Therefore, the dictionary has a list of dicts for each task. These submission dictionaries should appear in the same order as the test items from `test_challenges`. Additionally, you can provide two attempts for each test item. In fact, you **MUST** provide two attempts. If you only want to generate a single attempt, then just submit the same answer for both attempts (or submit an empty submission like the ones shown in the example snippit just above.\n",
    "\n",
    "Here is how we might create a blank submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e25a0fb-e206-4505-b597-8863c41c7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty submission dict for output\n",
    "submission = {}\n",
    "with open('../input/arc-prize-2024/arc-agi_evaluation_solutions.json', 'r') as sol_file:\n",
    "        solutions = json.load(sol_file)\n",
    "    \n",
    "# iterate over the test items and build up submission answers\n",
    "count = 0\n",
    "for key, task in tqdm(test_challenges.items()):\n",
    "\n",
    "    # Here are the task's training inputs and outputs\n",
    "    train_inputs = [item['input'] for item in task['train']]\n",
    "    train_outputs = [item['output'] for item in task['train']]\n",
    "\n",
    "    # Here we generate outputs for each test item.\n",
    "    submission[key] = []\n",
    "\n",
    "    for i, test_item in enumerate(task['test']):\n",
    "        input_grid = test_item['input'] \n",
    "        output_grid = solutions[key]\n",
    "        # this is just a placeholder, but would be where you might generate your predictions.\n",
    "        transformed = arc_planning(input_grid, output_grid)  # This should return a dict\n",
    "        \n",
    "        # Ensure 'transformed' is a dict and has the required keys\n",
    "        if isinstance(transformed, dict) and 'symmetrical' in transformed and 'color_changed' in transformed:\n",
    "            attempt_1 = transformed[\"symmetrical\"]  # Get symmetrical transformation\n",
    "            attempt_2 = transformed[\"color_changed\"]  # Get color-changed transformation\n",
    "\n",
    "            # Append to the submission\n",
    "            submission[key].append({\n",
    "                'attempt_1': attempt_1,\n",
    "                'attempt_2': attempt_2\n",
    "            })    \n",
    "        else:\n",
    "            print(f\"Warning: Transformed output for {input_grid} is not in the expected format.\")\n",
    "\n",
    "# Here we write the submissions to file, so that they will get evaluated\n",
    "with open('submission.json', 'w') as fp:\n",
    "    json.dump(submission, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79b7d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from collections import deque\n",
    "\n",
    "class ARCPuzzle:\n",
    "    \"\"\"\n",
    "    An eight puzzle class that can be used to test different search algorithms.\n",
    "    When first created the puzzle is in the solved state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state):\n",
    "        self.state = tuple((tuple(row) for row in state))\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.state)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, ARCPuzzle):\n",
    "            return self.state == other.state\n",
    "        return False\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        out = \"\"\n",
    "        for row in self.state:\n",
    "            out += str(row) + \"\\n\"\n",
    "        return out\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        Makes a deep copy of an ARCPuzzle object.\n",
    "        \"\"\"\n",
    "        new = ARCPuzzle(self.state)\n",
    "        return new\n",
    "\n",
    "    def randomize(self, num_shuffles):\n",
    "        \"\"\"\n",
    "        Randomizes an ARCPuzzle by executing a random action `num_suffles`\n",
    "        times.\n",
    "        \"\"\"\n",
    "        for i in range(num_shuffles):\n",
    "            actions = [a for a in self.legalActions()]\n",
    "            a = choice([a for a in self.legalActions()])\n",
    "            # print(actions, a)\n",
    "            self.executeAction(a)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def tophalf(self, grid):\n",
    "        \"\"\" upper half \"\"\"\n",
    "        return grid[:len(grid) // 2]\n",
    "\n",
    "\n",
    "    def rot90(self, grid):\n",
    "        \"\"\" clockwise rotation by 90 degrees \"\"\"\n",
    "        return tuple(zip(*grid[::-1]))\n",
    "\n",
    "\n",
    "    def hmirror(self, grid):\n",
    "        \"\"\" mirroring along horizontal \"\"\"\n",
    "        return grid[::-1]\n",
    "\n",
    "    def vmirror(self, grid):\n",
    "        \"\"\" mirroring along horizontal \"\"\"\n",
    "        return tuple(reversed(grid))\n",
    "\n",
    "    def lshift(self, grid):\n",
    "        return tuple([tuple([e for e in row if e != 0] + [0]*row.count(0))\n",
    "                      for row in grid])\n",
    "\n",
    "    def compress(self, grid):\n",
    "        \"\"\" removes frontiers \"\"\"\n",
    "        ri = [i for i, r in enumerate(grid) if len(set(r)) == 1]\n",
    "        ci = [j for j, c in enumerate(zip(*grid)) if len(set(c)) == 1]\n",
    "        return tuple([tuple([v for j, v in enumerate(r) if j not in ci])\n",
    "                      for i, r in enumerate(grid) if i not in ri])\n",
    "\n",
    "    def mapcolor(self, grid, a, b):\n",
    "        return tuple(tuple(b if e == a else e for e in row) for row in grid)\n",
    "\n",
    "    def trim(self, grid):\n",
    "        \"\"\" removes border \"\"\"\n",
    "        return tuple(r[1:-1] for r in grid[1:-1])\n",
    "\n",
    "    def executeAction(self, action):\n",
    "        \"\"\"\n",
    "        Executes an action to the ARCPuzzle object.\n",
    "\n",
    "        :param action: the action to execute\n",
    "        :type action: \"up\", \"left\", \"right\", or \"down\"\n",
    "        \"\"\"\n",
    "        if action == 'tophalf':\n",
    "            self.state = self.tophalf(self.state)\n",
    "        elif action == 'rot90':\n",
    "            self.state = self.rot90(self.state)\n",
    "        elif action == 'hmirror':\n",
    "            self.state = self.hmirror(self.state)\n",
    "        elif action == 'vmirror':\n",
    "            self.state = self.vmirror(self.state)\n",
    "        elif action == 'lshift':\n",
    "            self.state = self.lshift(self.state)\n",
    "        elif action == 'compress':\n",
    "            self.state = self.compress(self.state)\n",
    "        elif action[:8] == 'mapcolor':\n",
    "            args = action[9:-1].split(',')\n",
    "            self.state = self.mapcolor(self.state, int(args[0]), int(args[1]))\n",
    "\n",
    "    def legalActions(self):\n",
    "        \"\"\"\n",
    "        Returns an iterator to the legal actions that can be executed in the\n",
    "        current state.\n",
    "        \"\"\"\n",
    "        for action in ['tophalf', 'rot90', 'hmirror', 'vmirror', 'lshift', 'compress']:\n",
    "            yield action\n",
    "\n",
    "        for a in set(e for row in self.state for e in row):\n",
    "            for b in range(10):\n",
    "                if a == b:\n",
    "                    continue\n",
    "                yield f'mapcolor({a},{b})'\n",
    "\n",
    "\n",
    "# Defining the arc_planning function below the ArcPuzzle class\n",
    "def arc_planning(input_grid, output_grid) -> list[str]:\n",
    "    \"\"\"\n",
    "    Searches for a sequence of transformations to convert the input_grid into\n",
    "    the output_grid.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_grid: The initial grid that needs to be transformed.\n",
    "    - output_grid: The target grid to achieve.\n",
    "    - available_operations: List of primitive operations that can be used to transform the input grid.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of actions that transforms input_grid into output_grid.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    start_state = ARCPuzzle(input_grid)\n",
    "    goal_state = ARCPuzzle(output_grid)\n",
    "\n",
    "    queue = deque([(start_state, [])])\n",
    "    visited_nodes = set()\n",
    "\n",
    "    while queue:\n",
    "        current_state, actions = queue.popleft()\n",
    "\n",
    "        if current_state == goal_state:\n",
    "            return actions\n",
    "\n",
    "        visited_nodes.add(current_state)\n",
    "\n",
    "        for action in current_state.legalActions():\n",
    "            next_state = current_state.copy()\n",
    "            next_state.executeAction(action)\n",
    "\n",
    "            if next_state not in visited_nodes:\n",
    "                queue.append((next_state, actions + [action]))\n",
    "\n",
    "    return []\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     initial = ARCPuzzle([[7, 0, 7], [7, 0, 7], [7, 7, 0]])\n",
    "#     initial_copy = initial.copy()\n",
    "#     goal = initial.copy()\n",
    "#     goal.randomize(3)\n",
    "\n",
    "#     print(\"Puzzle being solved:\")\n",
    "#     print(initial)\n",
    "#     print(\"Goal =====>\")\n",
    "#     print(goal)\n",
    "#     print(\"-------------------\")\n",
    "\n",
    "#     ans = arc_planning(initial.state, goal.state)\n",
    "#     print(ans)\n",
    "#     print(initial_copy)\n",
    "#     for action in ans:\n",
    "#         initial_copy.executeAction(action)\n",
    "#         print(initial_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3d827-8f78-47d4-8bc7-3c07cfc996c2",
   "metadata": {},
   "source": [
    "Here is what our submission for the test task above looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07d83daa-496f-4cad-8550-876d115c4a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00576224 [{'attempt_1': [[3, 2], [2, 3]], 'attempt_2': [[3, 8], [7, 8]]}]\n"
     ]
    }
   ],
   "source": [
    "print(sample_task, submission[sample_task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f7599",
   "metadata": {},
   "source": [
    "# Scoring Your Submission\n",
    "\n",
    "If you do not want to wait for gradescope to score your solution, we have provided the following code to score your submission. Note that the maximum possibe score is 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39df0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_submission():\n",
    "    with open('../input/arc-prize-2024/arc-agi_evaluation_solutions.json', 'r') as sol_file:\n",
    "        solutions = json.load(sol_file)\n",
    "    \n",
    "    with open('submission.json', 'r') as sub_file:\n",
    "        submission = json.load(sub_file)\n",
    "    \n",
    "    overall_score = 0\n",
    "\n",
    "    for task in solutions:\n",
    "        score = 0\n",
    "        for i, answer in enumerate(solutions[task]):\n",
    "            attempt1_correct = submission[task][i]['attempt_1'] == answer\n",
    "            attempt2_correct = submission[task][i]['attempt_2'] == answer\n",
    "            score += int(attempt1_correct or attempt2_correct)\n",
    "\n",
    "        score /= len(solutions[task])\n",
    "\n",
    "        overall_score += score\n",
    "    \n",
    "\n",
    "    print(overall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6818bb2",
   "metadata": {},
   "source": [
    "You can run the above code by uncommenting the following code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b131fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "score_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6466c66-c324-44c2-8e05-3860e0fe1fdd",
   "metadata": {},
   "source": [
    "# Confused about where to get started? \n",
    "\n",
    "If you're not sure what an initial solution might look like, then consider looking at public notebooks here: https://www.kaggle.com/competitions/arc-prize-2024/code or joining the public discussion here: https://www.kaggle.com/competitions/arc-prize-2024/discussion.\n",
    "\n",
    "One example notebook that uses a very simple knowledge-based approach is this one: https://www.kaggle.com/code/michaelhodel/program-synthesis-starter-notebook/notebook, which conducts search over a space of domain specific block languages to form hypotheses and then applies these to test items."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
